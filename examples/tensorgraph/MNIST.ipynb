{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from deepchem.models.tensorgraph.layers import Layer, Input, Reshape, Flatten\n",
    "from deepchem.models.tensorgraph.layers import Dense, SoftMaxCrossEntropy, ReduceMean, SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
    "valid = dc.data.NumpyDataset(mnist.validation.images, mnist.validation.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tg = dc.models.TensorGraph(tensorboard=True, model_dir='/tmp/mnist')\n",
    "feature = Input(shape=(None, 784))\n",
    "tg.add_layer(feature)\n",
    "tg.add_feature(feature)\n",
    "\n",
    "# Images are square 28x28 (batch, height, width, channel)\n",
    "make_image = Reshape(shape=(-1, 28, 28, 1))\n",
    "tg.add_layer(make_image, parents=[feature])\n",
    "\n",
    "class Conv2d(Layer):\n",
    "    def __init__(self, num_outputs, kernel_size=5, **kwargs):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.kernel_size = kernel_size\n",
    "        super().__init__(**kwargs)\n",
    "    def __call__(self, *parents):\n",
    "        parent_tensor = parents[0].out_tensor\n",
    "        out_tensor = tf.contrib.layers.conv2d(parent_tensor,\n",
    "                                              num_outputs=self.num_outputs,\n",
    "                                              kernel_size = self.kernel_size,\n",
    "                                              padding=\"SAME\",\n",
    "                                              activation_fn=tf.nn.relu,\n",
    "                                              normalizer_fn=tf.contrib.layers.batch_norm)\n",
    "        self.out_tensor = tf.nn.max_pool(out_tensor, \n",
    "                                         ksize=[1, 2, 2, 1],\n",
    "                                         strides=[1, 2, 2, 1], \n",
    "                                         padding='SAME')\n",
    "        return self.out_tensor\n",
    "conv2d_1 = Conv2d(num_outputs=32)\n",
    "tg.add_layer(conv2d_1, parents=[make_image])\n",
    "\n",
    "conv2d_2 = Conv2d(num_outputs=64)\n",
    "tg.add_layer(conv2d_2, parents=[conv2d_1])\n",
    "\n",
    "flatten = Flatten()\n",
    "tg.add_layer(flatten, parents=[conv2d_2])\n",
    "\n",
    "dense1 = Dense(out_channels=1024, activation_fn=tf.nn.relu)\n",
    "tg.add_layer(dense1, parents=[flatten])\n",
    "\n",
    "dense2 = Dense(out_channels=10)\n",
    "tg.add_layer(dense2, parents=[dense1])\n",
    "\n",
    "label = Input(shape=(None, 10))\n",
    "tg.add_layer(label, parents=list())\n",
    "tg.add_label(label)\n",
    "\n",
    "smce = SoftMaxCrossEntropy()\n",
    "tg.add_layer(smce, parents=[label, dense2])\n",
    "\n",
    "loss = ReduceMean()\n",
    "tg.add_layer(loss, parents=[smce])\n",
    "tg.set_loss(loss)\n",
    "\n",
    "output = SoftMax()\n",
    "tg.add_layer(output, parents=[dense2])\n",
    "tg.add_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 0: Average loss 0.198305\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 1: Average loss 0.0536864\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 2: Average loss 0.0425871\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 3: Average loss 0.0336403\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 4: Average loss 0.028042\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 5: Average loss 0.0257894\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 6: Average loss 0.0187417\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 7: Average loss 0.01757\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Ending epoch 8: Average loss 0.0132135\n",
      "On batch 0\n",
      "On batch 50\n",
      "On batch 100\n",
      "On batch 150\n",
      "On batch 200\n",
      "On batch 250\n",
      "On batch 300\n",
      "On batch 350\n",
      "On batch 400\n",
      "On batch 450\n",
      "On batch 500\n",
      "On batch 550\n",
      "On batch 600\n",
      "On batch 650\n",
      "On batch 700\n",
      "On batch 750\n",
      "On batch 800\n",
      "On batch 850\n",
      "On batch 900\n",
      "On batch 950\n",
      "On batch 1000\n",
      "On batch 1050\n",
      "Loggin\n",
      "Ending epoch 9: Average loss 0.0121854\n",
      "TIMING: model fitting took 77.903 s\n"
     ]
    }
   ],
   "source": [
    "tg.fit(train, nb_epoch=10)\n",
    "tg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "class 0:auc=0.99987578265\n",
      "class 1:auc=0.999975981083\n",
      "class 2:auc=0.99987010958\n",
      "class 3:auc=0.999980197583\n",
      "class 4:auc=0.999985348139\n",
      "class 5:auc=0.999889990331\n",
      "class 6:auc=0.999762644083\n",
      "class 7:auc=0.999936670072\n",
      "class 8:auc=0.999936085657\n",
      "class 9:auc=0.999968609514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "print(\"Validation\")\n",
    "prediction = np.squeeze(tg.predict_on_batch(valid.X))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], thresh = roc_curve(valid.y[:, i], prediction[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(\"class %s:auc=%s\" % (i, roc_auc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
