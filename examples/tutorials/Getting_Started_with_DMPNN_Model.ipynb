{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hr-IW5sq5O1x"
      },
      "source": [
        "#  Introduction to DMPNN\n",
        "\n",
        "In this tutorial we will learn how to use DMPNN Model with the help of an example on an existing Tox21 dataset. This DMPNN model implementation is based on the paper: [Analyzing Learned Molecular Representations for Property Prediction](https://arxiv.org/pdf/1904.01561.pdf) and [Chemprop](https://github.com/chemprop/chemprop).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX2erW0ncj1W"
      },
      "source": [
        "\n",
        "\n",
        "# What is DMPNN?\n",
        "\n",
        "\n",
        "Directed ‚Äî Message Passing Neural Network (D-MPNN) model is a graph convolution network (GCN) built upon the existing Message Passing Neural Network (MPNN) architecture. The primary difference between the D-MPNN and regular MPNNs is in the nature of the messages being passed through the molecule during the message passing phase. While the general MPNN framework assumes messages are centered on atoms, the D-MPNN centers messages on bonds instead.<br>\n",
        "Specifically, the D-MPNN maintains two representations for the message centered on the bond between atoms ùë£ and ùë§: one from atom ùë£ to atom ùë§ and one from atom ùë§ to atom ùë£, hence the word Directed. Consequently, rather than aggregating information from neighboring atoms, the D-MPNN aggregates information from neighboring bonds. Each bond‚Äôs message is updated based on all incoming bond messages.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://miro.medium.com/max/4800/1*IZFd3FKXyhAjsMuUtcz5DQ.webp\" width=\"700\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "The motivation of this design is to prevent totters, that is, to avoid messages being passed along any path of the form v1 v2 ¬∑¬∑¬∑ vn where vi = vi+2 for some i. Such excursions are likely to introduce noise into the graph representation. Due to this structure, with messages centered on bonds and a distinction between the two directions of bond messages, the D-MPNN has greater control over the flow of information across the molecule and can therefore build more informative molecular representations.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukhViVz5jKe"
      },
      "source": [
        "## Colab\n",
        "\n",
        "This tutorial and the rest in this sequence are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Introduction_to_Graph_Convolutions.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc0FaUmP1tqP",
        "outputId": "9b4286e1-25c2-46bc-a5de-cedabeff667f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.8/dist-packages (2.7.2.dev20230203193045)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (from deepchem) (2022.9.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.0.2)\n",
            "Requirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem) (2022.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre deepchem"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N7krOH7L4U29"
      },
      "source": [
        "### Installing Dependencies required\n",
        "\n",
        "Setting up all the dependencies required. DMPNN Model requires torch, torch-geometric, torch-sparse and torch-scatter libraries to be installed. (Installation of torch-sparse and torch-scatter takes some time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLm2jCNb1yMa",
        "outputId": "5ecff3b7-1e4e-41ca-acc3-604af8d8c2f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deepchem[torch] in /usr/local/lib/python3.8/dist-packages (2.7.2.dev20230203193045)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.2.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (2022.9.4)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.21.6)\n",
            "Requirement already satisfied: scipy<1.9 in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.13.1+cu116)\n",
            "Requirement already satisfied: dgllife in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (0.3.1)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (0.9.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (1.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from deepchem[torch]) (0.14.1+cu116)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl->deepchem[torch]) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl->deepchem[torch]) (3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from dgl->deepchem[torch]) (4.64.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from dgl->deepchem[torch]) (5.9.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.8/dist-packages (from dgllife->deepchem[torch]) (0.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->deepchem[torch]) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem[torch]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->deepchem[torch]) (2022.7.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (0.6.0.post0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (2023.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (4.4.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning->deepchem[torch]) (23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from rdkit->deepchem[torch]) (7.1.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (3.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem[torch]) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl->deepchem[torch]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl->deepchem[torch]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl->deepchem[torch]) (4.0.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (from hyperopt->dgllife->deepchem[torch]) (4.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt->dgllife->deepchem[torch]) (0.16.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->deepchem[torch]) (1.3.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo->hyperopt->dgllife->deepchem[torch]) (2.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.16.tar.gz (208 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.16-cp38-cp38-linux_x86_64.whl size=1077033 sha256=d66f9de0847900e2f1faad7deb2ad24041d416832ba1e238dc2a9ae423f4cf0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/f5/41/86610d3a3ce0bec241d8549ecdd6c7e07fe000e041616cfcd6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.16\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.0.tar.gz (106 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.0-cp38-cp38-linux_x86_64.whl size=481031 sha256=b688c6869f55a30443d385e0a8f354d89e3c26cb3c84cdaac0d665bc8667b08b\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/7f/4f/cf072bea3b6efe4561de2db3603ebbd8718c134c24caab8281\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem[torch]\n",
        "!pip install torch-geometric\n",
        "!pip install torch-sparse\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.0+${CUDA}.html  # noqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RYNdat6fYqA"
      },
      "outputs": [],
      "source": [
        "import deepchem as dc\n",
        "import numpy as np\n",
        "from deepchem.models import DMPNNModel\n",
        "from rdkit.Chem import Descriptors"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YJGMi4332DFA"
      },
      "source": [
        "### DMPNN Featurizer\n",
        "\n",
        "DMPNNFeaturizer class is a featurizer for Directed Message Passing Neural Network (D-MPNN) implementation\n",
        "\n",
        "The default node representation are constructed by concatenating the following values,and the feature length is 133.\n",
        "1. Atomic num - A one-hot vector of this atom, in a range of first 100 atoms.\n",
        "2. Degree - A one-hot vector of the degree (0-5) of this atom.\n",
        "3. Formal charge - Integer electronic charge, -1, -2, 1, 2, 0.\n",
        "4. Chirality - A one-hot vector of the chirality tag (0-3) of this atom.\n",
        "5. Number of Hydrogens - A one-hot vector of the number of hydrogens (0-4) that this atom connected.\n",
        "6. Hybridization - A one-hot vector of \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\".\n",
        "7. Aromatic - A one-hot vector of whether the atom belongs to an aromatic ring.\n",
        "8. Mass - Atomic mass * 0.01\n",
        "\n",
        "The default edge representation are constructed by concatenating the following values, and the feature length is 14.\n",
        "\n",
        "1. Bond type - A one-hot vector of the bond type, \"single\", \"double\", \"triple\", or \"aromatic\".\n",
        "2. Same ring - A one-hot vector of whether the atoms in the pair are in the same ring.\n",
        "3. Conjugated - A one-hot vector of whether this bond is conjugated or not. \n",
        "4. Stereo - A one-hot vector of the stereo configuration (0-5) of a bond.\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSlubt0hbPPn",
        "outputId": "662a5762-dffc-4252-e256-967227129956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type of featurized data:- <class 'deepchem.feat.graph_data.GraphData'>\n",
            "[num_nodes, num_node_features]:- (6, 133)\n",
            "[num_edges, num_edge_features]:- (12, 14)\n"
          ]
        }
      ],
      "source": [
        "# Example of Featurized data\n",
        "\n",
        "smiles = [\"C1=CC=CN=C1\"]\n",
        "featurizer = dc.feat.DMPNNFeaturizer()\n",
        "out = featurizer.featurize(smiles)\n",
        "print(\"Type of featurized data:-\", type(out[0]))\n",
        "print(\"[num_nodes, num_node_features]:-\", out[0].node_features.shape)\n",
        "print(\"[num_edges, num_edge_features]:-\", out[0].edge_features.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PikK2m2gevW7"
      },
      "source": [
        "### Parameters of DMPNNFeaturizer Class are:-\n",
        "1. features_generator - It takes a List of global feature generators to be used during featurization. The input should be in the form of one of the following strings. Its default value is None.<br>\n",
        "Available Feature Generators are-  \n",
        "* \"morgan\" - Uses CircularFingerprint class with feature size 2048.\n",
        "* \"morgan_count\" - Uses CircularFingerprint class with feature size 2048.\n",
        "* \"rdkit_desc\" - Uses RDKitDescriptors class without normalization with feature size 200.\n",
        "* \"rdkit_desc_normalized\" - Uses RDKitDescriptors class with normalization with feature size 200.\n",
        "\n",
        "To know more, you can refer to this- [feature generators](https://github.com/deepchem/deepchem/blob/2388d66798dbbff732520824ad36143e0e5f1b1b/deepchem/feat/molecule_featurizers/dmpnn_featurizer.py#L47-L60)\n",
        "2. is_adding_hs - It takes bool value, whether to add Hydrogen atoms or not. It's default value is False.\n",
        "3. use_original_atom_ranks - Whether to use original atom mapping or canonical atom mapping. It's default value is False.\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ifgM0ysFHDzc"
      },
      "source": [
        "#### More on RDKitDescriptors\n",
        "\n",
        "Currently, there are 208 RDKitDescriptors present in RDKit Library, But the normalizing cdf parameters are not available for BCUT2D descriptor.(BCUT2D_MWHI, BCUT2D_MWLOW, BCUT2D_CHGHI, BCUT2D_CHGLO, BCUT2D_LOGPHI, BCUT2D_LOGPLOW, BCUT2D_MRHI, BCUT2D_MRLOW).\n",
        "Therefore, size=200 for \"rdkit_desc_normalized\" or \"rdkit_desc\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0UJKtwCkI23",
        "outputId": "e6d913c2-d4b8-46d9-d7ff-be4cd93c8d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature size of rdkit_desc/rdkit_desc_normalized = 200\n"
          ]
        }
      ],
      "source": [
        "total_descriptors = len(Descriptors.descList)\n",
        "# After Ignoring 8 Bcut2D descriptors that we are not using DMPNN.\n",
        "rdkit_feature_size = total_descriptors - 8\n",
        "print(\"Feature size of rdkit_desc/rdkit_desc_normalized =\", rdkit_feature_size)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GEAQqkyHKmZv"
      },
      "source": [
        "## Training DMPNN Model\n",
        "Let's use the MoleculeNet suite to load the Tox21 dataset. To featurize the data in a way that graph convolutional networks can use, we set the featurizer option to 'DMPNNFeaturizer'. The MoleculeNet call returns a training set, a validation set, and a test set for us to use. It also returns tasks, a list of the task names, and transformers, a list of data transformations that were applied to preprocess the dataset. (Most deep networks are quite finicky and require a set of data transformations to ensure that training proceeds stably.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMi2V8Jncj1W"
      },
      "outputs": [],
      "source": [
        "# Load Tox21 dataset\n",
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(\n",
        "    featurizer=dc.feat.DMPNNFeaturizer(\n",
        "        features_generators=[\"rdkit_desc_normalized\"]),\n",
        "    splitter='scaffold')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uditTZEyAVE0",
        "outputId": "58aad650-711f-4f68-a394-5dac1dfd070f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset is featurized\n",
            "6264 783 784\n",
            "[GraphData(node_features=[11, 133], edge_index=[2, 20], edge_features=[20, 14], global_features=[200])\n",
            " GraphData(node_features=[20, 133], edge_index=[2, 38], edge_features=[38, 14], global_features=[200])\n",
            " GraphData(node_features=[10, 133], edge_index=[2, 18], edge_features=[18, 14], global_features=[200])\n",
            " GraphData(node_features=[21, 133], edge_index=[2, 36], edge_features=[36, 14], global_features=[200])\n",
            " GraphData(node_features=[10, 133], edge_index=[2, 18], edge_features=[18, 14], global_features=[200])]\n"
          ]
        }
      ],
      "source": [
        "train_dataset, valid_dataset, test_dataset = tox21_datasets\n",
        "print('dataset is featurized')\n",
        "\n",
        "print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
        "print(train_dataset.X[:5])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VXYSQsVZop-1"
      },
      "source": [
        "The DMPNN model has 2 phases, message-passing phase and read-out phase.\n",
        "\n",
        "  - The goal of the message-passing phase is to generate 'hidden states of all the atoms in the molecule' using encoders.\n",
        "  - Next in read-out phase, the features are passed into feed-forward neural network to get the task-based prediction.\n",
        "\n",
        "### Parameters<br>\n",
        "General Parameters\n",
        "1.   mode - It specifies the model type - classification or regression,\n",
        "default type is 'regression'.\n",
        "2.   n_classes - The number of classes to predict (used only in classification mode), default value is 3.\n",
        "3.   n_tasks - The number of tasks, default value is 1.\n",
        "4.   batch_size - The number of datapoints in a batch, default value is 1.\n",
        "5.   global_features_size - Size of the global features vector (based on the global featurizers used during featurization).\n",
        "6.   use_default_fdim - If `True`, self.atom_fdim and self.bond_fdim are initialized using values from the GraphConvConstants class.\n",
        "      If `False`, self.atom_fdim and self.bond_fdim are initialized from the values provided.\n",
        "7.    atom_fdim - Specifies the dimension of atom feature vector.\n",
        "8.    bond_fdim - Specifies the dimension of bond feature vector.\n",
        "\n",
        "Encoder parameters\n",
        "1.    enc_hidden - Specifies the size of hidden layer in the encoder layer.\n",
        "2.   depth - It is the no of message passing steps.\n",
        "3.   bias - If `True`, dense layers will use bias vectors.\n",
        "4.   enc_activation - Activation function to be used in the encoder layer. The different activation functions are - 'relu' for ReLU, 'leakyrelu' for LeakyReLU, 'prelu' for PReLU, 'tanh' for TanH, 'selu' for SELU, and 'elu' for ELU.\n",
        "5.   enc_dropout_p - Dropout probability for the encoder layer.\n",
        "6.   aggregation - Aggregation type to be used in the encoder layer.\n",
        "      Can choose between 'mean', 'sum', and 'norm'.\n",
        "7.   aggregation_norm - Value required if `aggregation` type is 'norm'.\n",
        "\n",
        "Feed Forward Parameters\n",
        "1.   ffn_hidden - Size of hidden layer in the feed-forward network layer.\n",
        "2.   ffn_activation - Activation function to be used in feed-forward network layer. Can choose between 'relu' for ReLU, 'leakyrelu' for LeakyReLU, 'prelu' for PReLU, 'tanh' for TanH, 'selu' for SELU, and 'elu' for ELU.\n",
        "3.   ffn_layers - Number of layers in the feed-forward network layer.\n",
        "4.    ffn_dropout_p - Dropout probability for the feed-forward network layer.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ymjD1ZpuPGZq"
      },
      "source": [
        "#### NOTE:- Do not forget to provide value for \"global_features_size\" if you have used one or more feature generators as discussed earlier.\n",
        "If you have used more than one feature generator, then \"global_features_size\" is sum of the respective feature sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z1xBrWHAW7H",
        "outputId": "c9b34a7c-4526-40ae-a62c-efc12866f258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.15509110689163208"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialise the model\n",
        "model = DMPNNModel(n_tasks=len(tox21_tasks),\n",
        "                   n_classes=2,\n",
        "                   mode='classification',\n",
        "                   batch_size=50,\n",
        "                   global_features_size=200)\n",
        "\n",
        "# Model training\n",
        "print(\"Training model\")\n",
        "model.fit(train_dataset, nb_epoch=30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgS7mKzN3XYZ"
      },
      "source": [
        "Let's try to evaluate the performance of the model we've trained. For this, we need to define a metric, a measure of model performance. `dc.metrics` holds a collection of metrics already. For this dataset, it is standard to use the ROC-AUC score, the area under the receiver operating characteristic curve (which measures the tradeoff between precision and recall). Luckily, the ROC-AUC score is already available in DeepChem. \n",
        "\n",
        "To measure the performance of the model under this metric, we can use the convenience function `model.evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3rxreoaAhzf",
        "outputId": "8840ffd1-90cf-4e38-ec59-ce136135f1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model\n",
            "Train scores:  {'mean-roc_auc_score': 0.9831147857676159}\n",
            "Validation scores:  {'mean-roc_auc_score': 0.7535253916851191}\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "\n",
        "print(\"Evaluating model\")\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
        "\n",
        "print(\"Train scores: \", train_scores)\n",
        "print(\"Validation scores: \", valid_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j1FrVn88cj17"
      },
      "source": [
        "# Congratulations! Time to join the Community!\n",
        "\n",
        "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
        "\n",
        "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
        "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
        "\n",
        "## Join the DeepChem Gitter\n",
        "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deepchem",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "aaf9ca60d67e8bd5d8460c946e93786cb3bd904bba1eef834567c0c3a533f993"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
