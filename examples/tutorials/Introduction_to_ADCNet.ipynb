{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6f0b77",
   "metadata": {},
   "source": [
    "## **Introduction to ADCNet: Predicting ADC Activity with DeepChem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef1a9d",
   "metadata": {},
   "source": [
    "Antibody-Drug Conjugates (ADCs) can transform cancer treatment in the era of precision medicine by enabling targeted delivery of potent drugs to cancer cells, minimizing damage to healthy tissues. However, designing effective ADCs remains challenging due to the complex relationship between their molecular structures and therapeutic activities. To address this, we introduce ADCNet [[1]](#1), a unified deep learning framework that facilitates the rational design of ADCs. ADCNet integrates the protein representation learning model ESM-2 for antibody and antigen sequences with the small-molecule representation model FG-BERT for linker and payload SMILES strings, alongside the Drug-Antibody Ratio (DAR) value, to predict ADC activity with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d633c53",
   "metadata": {},
   "source": [
    "In this tutorial, we will explore how to predict the therapeutic activity of Antibody-Drug Conjugates (ADCs) using ADCNet, a unified deep learning framework implemented in DeepChem. To build a foundational understanding of ADCs, refer to the \"Introduction to Antibody-Drug Conjugates\" [[2]](#2) notebook available in the DeepChem tutorials before proceeding with this guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8451a",
   "metadata": {},
   "source": [
    "# **Colab**\n",
    "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/ADCNet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b88c1d",
   "metadata": {},
   "source": [
    "## **Background on Drug Discovery and ADCs**\n",
    "\n",
    "With advancements in molecular biology, target-oriented drug discovery has become the dominant approach, aiming to identify selective and effective clinical candidates. Traditional small molecule inhibitors have shown success but suffer from limitations such as off-target effects, narrow therapeutic windows, and drug resistance. The development of monoclonal antibodies has addressed some of these issues by leveraging specific antigen expression, though their effectiveness against heterogeneous cancer cells remains limited. Antibody-Drug Conjugates (ADCs) emerged as an innovative solution, combining the targeting precision of antibodies with the cytotoxicity of toxins via suitable linkers, enhancing therapeutic efficacy while minimizing harm to healthy cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb6044",
   "metadata": {},
   "source": [
    "## **Overview of the model architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36331efe",
   "metadata": {},
   "source": [
    "We have three steps of execution first is processing different types of input data; second, generating embeddings from these inputs using pretrained models; and lastly, concteanting the embeddings and feeding them into a Multilayer Perceptron (MLP) to predict the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cebf7",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cd28e",
   "metadata": {},
   "source": [
    "So lets know about the inputs, we have three different forms of inputs. \n",
    "\n",
    "(I) Protein Sequences:\n",
    "\n",
    "- Antibody Heavy Chain: Protein sequence of the antibody's heavy chain.\n",
    "- Antibody Light Chain: Protein sequence of the antibody's light chain.\n",
    "- Antigen: Protein sequence of the target antigen.\n",
    "\n",
    "(II) Small Molecules (SMILES representations):\n",
    "\n",
    "- Linker: SMILES string representing the chemical structure of the linker.\n",
    "- Payload: SMILES string representing the chemical structure of the cytotoxic payload.\n",
    "\n",
    "(III) Numerical Value:\n",
    "\n",
    "- Drugâ€“Antibody Ratio (DAR): A value indicating the average number of payload molecules attached to each antibody.\n",
    "\n",
    "Each input is processed separately to extract its unique features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c21ff",
   "metadata": {},
   "source": [
    "### Generating Embeddings\n",
    "\n",
    "ADCNet uses pre-trained language models to transform the inputs into embeddings:\n",
    "\n",
    "- Protein sequences (antibody heavy chain, antibody light chain, and antigen sequences) are processed using ESM-2 (Evolutionary Scale Modeling) [[3]](#3), a Transformer-based protein language model. ESM-2 converts these sequences into dense embeddings that encode their structural and functional properties.\n",
    "\n",
    "- SMILES representations of the linker and payload are processed using ChemBERTA. ChemBERTA generates embeddings that capture the chemical properties of these small molecules. <br>\n",
    "\n",
    "   **Note**: While the original ADCNet paper used FGBERT, ChemBERTA is utilized here due to its availability and effectiveness in the DeepChem framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7347c06",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "After generating the embeddings,\n",
    "\n",
    "- The embeddings from the three protein sequences (heavy chain, light chain, and antigen), the two small molecules (linker and payload), and the processed DAR value are concatenated into a single feature vector.\n",
    "- This combined feature vector is fed into a Multilayer Perceptron (MLP) consisting of two fully connected layers with nonlinear activation functions. The MLP analyzes the concatenated features to predict the ADC's therapeutic activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f90a13",
   "metadata": {},
   "source": [
    "<img src=\"assets/adcnet_diagram.png\" alt=\"image.png\" height=\"1200\" width=\"900\"> <br>\n",
    "---\n",
    "\n",
    "<small>*Diagram illustrating the ADCNet architecture*</small> [[4]](#4) (A) The mechanism of action of ADCs. (B) The network architecture of ADCNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae7db8",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e30b4e",
   "metadata": {},
   "source": [
    "Let's first setup and install necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975c6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.24.4)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.3.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.13.3)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.10.1)\n",
      "Requirement already satisfied: rdkit in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (2024.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2025.2)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from rdkit->deepchem) (10.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn->deepchem) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "# install the necessary libraries\n",
    "\n",
    "!pip install deepchem\n",
    "!pip install numpy\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install transformers\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e65167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66558ea9",
   "metadata": {},
   "source": [
    "### Data Collection and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0abdc",
   "metadata": {},
   "source": [
    "We will be using ADCdb which is originally used by ADCNet, and accessible at [[5]](#5). It contains data on 6,572 ADCs, including 359 approved by the FDA or in clinical trials, 501 in preclinical testing, 819 with in-vivo testing data, 1,868 with cell line or target testing data, and 3,025 without such testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b9644",
   "metadata": {},
   "source": [
    "Here we will be using the preprocessed data for convinience found at [[6]](#6). Lets get a look at the dataset, the original dataset is ADCdb ,with data on ADCs, and we include this data from ADCNet, which is preprocessed. This can be found in assets folder or you can find the same in ADCdb github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have data of 435 ADCs\n"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "file_path = \"assets/adcdb.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f'We have data of {len(df)} ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efb5dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'ADC ID',\n",
       " 'ADC Name',\n",
       " 'Antibody Name',\n",
       " 'Antibody Heavy Chain Sequence',\n",
       " 'Antibody Light Chain Sequence',\n",
       " 'Antigen Sequence',\n",
       " 'Payload Isosmiles',\n",
       " 'Linker Isosmiles',\n",
       " 'DAR',\n",
       " 'labelï¼ˆ10nmï¼‰',\n",
       " 'labelï¼ˆ100nmï¼‰',\n",
       " 'labelï¼ˆ1nmï¼‰',\n",
       " 'labelï¼ˆ1000nmï¼‰',\n",
       " 'DAR_val']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba139eff",
   "metadata": {},
   "source": [
    "Lets have a preview of the dataset we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2407728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ADC ID</th>\n",
       "      <th>ADC Name</th>\n",
       "      <th>Antibody Name</th>\n",
       "      <th>Antibody Heavy Chain Sequence</th>\n",
       "      <th>Antibody Light Chain Sequence</th>\n",
       "      <th>Antigen Sequence</th>\n",
       "      <th>Payload Isosmiles</th>\n",
       "      <th>Linker Isosmiles</th>\n",
       "      <th>DAR</th>\n",
       "      <th>labelï¼ˆ10nmï¼‰</th>\n",
       "      <th>labelï¼ˆ100nmï¼‰</th>\n",
       "      <th>labelï¼ˆ1nmï¼‰</th>\n",
       "      <th>labelï¼ˆ1000nmï¼‰</th>\n",
       "      <th>DAR_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DRG0ABJAM</td>\n",
       "      <td>Trastuzumab-BCN-HydraSpace-Val-Cit-PABC-Gly-Ca...</td>\n",
       "      <td>Trastuzumab</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>CCN(C(=O)CN)C1COC(OC2C(OC3C#C/C=C\\C#CC4(O)CC(=...</td>\n",
       "      <td>CC(C)C(NC(=O)OCCN(CCOC(=O)NC(C(=O)NC(CCCNC(N)=...</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DRG0ZBATX</td>\n",
       "      <td>Anti-KIT NEG087?SSNPP-DM3</td>\n",
       "      <td>Anti-KIT mAb NEG087</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFSDYYMAWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...</td>\n",
       "      <td>MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...</td>\n",
       "      <td>C[C@@H]1[C@@H]2C[C@]([C@@H](/C=C/C=C(/CC3=CC(=...</td>\n",
       "      <td>CC(S)CCC(N)=O</td>\n",
       "      <td>3.0-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DRG0XJKXB</td>\n",
       "      <td>Trastuzumab-C239I-SG3400</td>\n",
       "      <td>Engineered trastuzumab</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>C=C1CC2C=Nc3cc(OCCCOc4cc5c(cc4OC)C(=O)N4CC(=C)...</td>\n",
       "      <td>C[C@@H](C(=O)NC1=CC=C(C=C1)CO)NC(=O)[C@H](C(C)...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DRG0ZOYQV</td>\n",
       "      <td>Datopotamab deruxtecan</td>\n",
       "      <td>Datopotamab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTTAGMQWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCKASQDVSTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MARGPGLAPPPLRLPLLLLVLAAVTGHTAAQDNCTCPTNKMTVCSP...</td>\n",
       "      <td>CC[C@@]1(C2=C(COC1=O)C(=O)N3CC4=C5[C@H](CCC6=C...</td>\n",
       "      <td>C1=CC=C(C=C1)C[C@@H](C(=O)NCC(=O)O)NC(=O)CNC(=...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DRG0COMTY</td>\n",
       "      <td>Telisotuzumab vedotin</td>\n",
       "      <td>Telisotuzumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYIFTAYTMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSESVDSYANSFLHWYQQKPGQ...</td>\n",
       "      <td>MKAPAVLAPGILVLLFTLVQRSNGECKEALAKSEMNVNMKYQLPNF...</td>\n",
       "      <td>CC[C@H](C)[C@@H]([C@@H](CC(=O)N1CCC[C@H]1[C@@H...</td>\n",
       "      <td>CC(C)[C@@H](C(=O)N[C@@H](CCCNC(=O)N)C(=O)NC1=C...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     ADC ID                                           ADC Name  \\\n",
       "0      0  DRG0ABJAM  Trastuzumab-BCN-HydraSpace-Val-Cit-PABC-Gly-Ca...   \n",
       "1      1  DRG0ZBATX                          Anti-KIT NEG087?SSNPP-DM3   \n",
       "2      2  DRG0XJKXB                           Trastuzumab-C239I-SG3400   \n",
       "3      3  DRG0ZOYQV                             Datopotamab deruxtecan   \n",
       "4      4  DRG0COMTY                              Telisotuzumab vedotin   \n",
       "\n",
       "            Antibody Name                      Antibody Heavy Chain Sequence  \\\n",
       "0             Trastuzumab  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "1     Anti-KIT mAb NEG087  EVQLVESGGGLVQPGGSLRLSCAASGFTFSDYYMAWVRQAPGKGLE...   \n",
       "2  Engineered trastuzumab  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "3             Datopotamab  QVQLVQSGAEVKKPGASVKVSCKASGYTFTTAGMQWVRQAPGQGLE...   \n",
       "4           Telisotuzumab  QVQLVQSGAEVKKPGASVKVSCKASGYIFTAYTMHWVRQAPGQGLE...   \n",
       "\n",
       "                       Antibody Light Chain Sequence  \\\n",
       "0  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...   \n",
       "2  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "3  DIQMTQSPSSLSASVGDRVTITCKASQDVSTAVAWYQQKPGKAPKL...   \n",
       "4  DIVMTQSPDSLAVSLGERATINCKSSESVDSYANSFLHWYQQKPGQ...   \n",
       "\n",
       "                                    Antigen Sequence  \\\n",
       "0  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...   \n",
       "1  MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...   \n",
       "2  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...   \n",
       "3  MARGPGLAPPPLRLPLLLLVLAAVTGHTAAQDNCTCPTNKMTVCSP...   \n",
       "4  MKAPAVLAPGILVLLFTLVQRSNGECKEALAKSEMNVNMKYQLPNF...   \n",
       "\n",
       "                                   Payload Isosmiles  \\\n",
       "0  CCN(C(=O)CN)C1COC(OC2C(OC3C#C/C=C\\C#CC4(O)CC(=...   \n",
       "1  C[C@@H]1[C@@H]2C[C@]([C@@H](/C=C/C=C(/CC3=CC(=...   \n",
       "2  C=C1CC2C=Nc3cc(OCCCOc4cc5c(cc4OC)C(=O)N4CC(=C)...   \n",
       "3  CC[C@@]1(C2=C(COC1=O)C(=O)N3CC4=C5[C@H](CCC6=C...   \n",
       "4  CC[C@H](C)[C@@H]([C@@H](CC(=O)N1CCC[C@H]1[C@@H...   \n",
       "\n",
       "                                    Linker Isosmiles      DAR  labelï¼ˆ10nmï¼‰  \\\n",
       "0  CC(C)C(NC(=O)OCCN(CCOC(=O)NC(C(=O)NC(CCCNC(N)=...     1.86            0   \n",
       "1                                      CC(S)CCC(N)=O  3.0-4.0            0   \n",
       "2  C[C@@H](C(=O)NC1=CC=C(C=C1)CO)NC(=O)[C@H](C(C)...     1.71            1   \n",
       "3  C1=CC=C(C=C1)C[C@@H](C(=O)NCC(=O)O)NC(=O)CNC(=...        4            1   \n",
       "4  CC(C)[C@@H](C(=O)N[C@@H](CCCNC(=O)N)C(=O)NC1=C...      3.1            1   \n",
       "\n",
       "   labelï¼ˆ100nmï¼‰  labelï¼ˆ1nmï¼‰  labelï¼ˆ1000nmï¼‰  DAR_val  \n",
       "0             0           0              0     1.86  \n",
       "1             0           0              0     3.50  \n",
       "2             1           1              1     1.71  \n",
       "3             1           1              1     4.00  \n",
       "4             1           1              1     3.10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c4f60",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c28b9c",
   "metadata": {},
   "source": [
    "Here we will use the smallest version of ESM-2 (esm2_t6_8M_UR50D), trained with 6 layers and 8 Million parameters. Larger ESM-2 models are available in the Transformers library of Hugging Face, see [here](https://huggingface.co/facebook/esm2_t6_8M_UR50D).\n",
    "\n",
    "We will now generate embeddings for the antibody heavy chain, light chain, and antigen protein sequences in our dataset using ESM-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c03f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load ESM-2 8M parameters model\n",
    "model_esm = 'facebook/esm2_t6_8M_UR50D'\n",
    "\n",
    "tokenizer_esm = EsmTokenizer.from_pretrained(model_esm)\n",
    "esm = EsmModel.from_pretrained(model_esm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1808a5",
   "metadata": {},
   "source": [
    "For small molecules we will use ChemBERTA for generating embedddings from SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04ad4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ChemBERTa model and tokenizer\n",
    "model_chemberta = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "tokenizer_chemberta = AutoTokenizer.from_pretrained(model_chemberta)\n",
    "chemberta = AutoModel.from_pretrained(model_chemberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bcf5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequences and SMILES from the dataframe\n",
    "\n",
    "heavy_chains = df['Antibody Heavy Chain Sequence'].astype(str).tolist()\n",
    "light_chains = df['Antibody Light Chain Sequence'].astype(str).tolist()\n",
    "antigens = df['Antigen Sequence'].astype(str).tolist()\n",
    "linkers = df['Linker Isosmiles'].tolist()\n",
    "payloads = df['Payload Isosmiles'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70a32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dar_values = df['DAR_val'].values.reshape(-1, 1)  # reshape for scaler\n",
    "\n",
    "# Normalize DAR\n",
    "scaler = StandardScaler()\n",
    "dar_scaled = scaler.fit_transform(dar_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84348bda",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd177348",
   "metadata": {},
   "source": [
    "Let's first generate embeddings from protein sequences using ESM-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67dd7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(sequences):\n",
    "    embeddings = []\n",
    "\n",
    "    for seq in tqdm(sequences, desc=\"Generating embeddings\"):\n",
    "        inputs = tokenizer_esm(\n",
    "            seq,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            is_split_into_words=False\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = esm(**inputs)\n",
    "        \n",
    "        # Extract CLS token\n",
    "        cls_emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "        embeddings.append(cls_emb)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750d918",
   "metadata": {},
   "source": [
    "Now we can use the above function to generate embeddings by passing the sequences as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69770e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for heavy chains, light chains, and antigens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 435/435 [03:39<00:00,  1.99it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 435/435 [03:46<00:00,  1.92it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 435/435 [04:02<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings from protein sequences\n",
    "print(\"Generating embeddings for heavy chains, light chains, and antigens...\")\n",
    "\n",
    "heavy_embeddings = get_embeddings(heavy_chains)\n",
    "light_embeddings = get_embeddings(light_chains)\n",
    "antigen_embeddings = get_embeddings(antigens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19cde5",
   "metadata": {},
   "source": [
    "Now lets move on to genrate embeddings for SMILES of payload and linker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d4037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embedding for a single SMILES string\n",
    "def get_smiles_embedding(smiles: str):\n",
    "    inputs = tokenizer_chemberta(smiles, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = chemberta(**inputs)\n",
    "        # Use the CLS token representation (first token)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]  # shape: (1, hidden_size)\n",
    "        return embedding.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef64263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for a list of SMILES\n",
    "def generate_embeddings(smiles_list):\n",
    "    embeddings = []\n",
    "    for smi in tqdm(smiles_list):\n",
    "        try:\n",
    "            emb = get_smiles_embedding(smi)\n",
    "            embeddings.append(emb)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {smi}: {e}\")\n",
    "            embeddings.append(None)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a49ec",
   "metadata": {},
   "source": [
    "Embeddings from payload smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4679ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 435/435 [00:09<00:00, 44.27it/s]\n"
     ]
    }
   ],
   "source": [
    "payload_embeddings = generate_embeddings(payloads) # embeddings from payload smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea3716",
   "metadata": {},
   "source": [
    "Embeddings from linker smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c902acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 435/435 [00:06<00:00, 62.52it/s]\n"
     ]
    }
   ],
   "source": [
    "linker_embeddings = generate_embeddings(linkers) # embeddings from linker smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9665ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "adc_embeddings = []\n",
    "\n",
    "num_adcs = len(heavy_embeddings)\n",
    "\n",
    "for i in range(num_adcs):\n",
    "    heavy = heavy_embeddings[i]\n",
    "    light = light_embeddings[i]\n",
    "    antigen = antigen_embeddings[i]\n",
    "    payload = payload_embeddings[i]\n",
    "    linker = linker_embeddings[i]\n",
    "\n",
    "    # Convert to tensor if not already\n",
    "    for name, emb in zip(['heavy', 'light', 'antigen'], [heavy, light, antigen]):\n",
    "        if not isinstance(emb, torch.Tensor):\n",
    "            locals()[name] = torch.tensor(emb)\n",
    "    if not isinstance(payload, torch.Tensor):\n",
    "        payload = torch.tensor(payload)\n",
    "    if not isinstance(linker, torch.Tensor):\n",
    "        linker = torch.tensor(linker)\n",
    "\n",
    "    # Ensure 1D shape\n",
    "    if payload.dim() == 0:\n",
    "        payload = payload.unsqueeze(0)\n",
    "    if linker.dim() == 0:\n",
    "        linker = linker.unsqueeze(0)\n",
    "\n",
    "    # Concatenate embeddings\n",
    "    full_emb = torch.cat([\n",
    "        heavy,\n",
    "        light,\n",
    "        antigen,\n",
    "        payload,\n",
    "        linker\n",
    "    ])  # shape: [combined_dim]\n",
    "\n",
    "    adc_embeddings.append(full_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f92bbf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload shape: (768,)\n",
      "Linker shape: (768,)\n",
      "Heavy shape: torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "print(\"Payload shape:\", payload_embeddings[0].shape)\n",
    "print(\"Linker shape:\", linker_embeddings[0].shape)\n",
    "print(\"Heavy shape:\", heavy_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deebda13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2496])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c19151",
   "metadata": {},
   "source": [
    "### MODEL- MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c883d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_batch_tensor = torch.stack(adc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b803f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([435, 2496])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc_batch_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2b4b",
   "metadata": {},
   "source": [
    "#### MLP defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5720cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([435, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from deepchem.models.torch_models.layers import MultilayerPerceptron\n",
    "\n",
    "# Define the model\n",
    "model_mlp = MultilayerPerceptron(\n",
    "    d_input= 2496,\n",
    "    d_output=1,\n",
    "    d_hidden=(1024, 256),\n",
    "    dropout=0.0,\n",
    "    activation_fn='relu'\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "op = model_mlp(adc_batch_tensor)\n",
    "print(op.shape)  # [435, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b2cb2",
   "metadata": {},
   "source": [
    "### Model training from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e48b3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48bfa282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the label\n",
    "label_col = \"labelï¼ˆ100nmï¼‰\"\n",
    "labels = df[label_col].values  # 0 or 1\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "y = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)  # shape: [10, 1] assuming 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfcbbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(adc_batch_tensor, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "173fad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "mode = model_mlp  # using the MLP defined\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mode.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afe4e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82399bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.5348 | Val Loss: 0.2351\n",
      "Epoch 10 | Train Loss: 0.1903 | Val Loss: 0.1788\n",
      "Epoch 20 | Train Loss: 0.1738 | Val Loss: 0.1592\n",
      "Epoch 30 | Train Loss: 0.1578 | Val Loss: 0.1559\n",
      "Epoch 40 | Train Loss: 0.1450 | Val Loss: 0.1531\n",
      "Epoch 50 | Train Loss: 0.1327 | Val Loss: 0.1525\n",
      "Epoch 60 | Train Loss: 0.1208 | Val Loss: 0.1503\n",
      "Epoch 70 | Train Loss: 0.1093 | Val Loss: 0.1484\n",
      "Epoch 80 | Train Loss: 0.0984 | Val Loss: 0.1457\n",
      "Epoch 90 | Train Loss: 0.0884 | Val Loss: 0.1425\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_mlp.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = mode(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_mlp.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_mlp(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val)\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5286a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8293],\n",
      "        [0.9015],\n",
      "        [0.0860],\n",
      "        [0.9043],\n",
      "        [0.8328]])\n"
     ]
    }
   ],
   "source": [
    "model_mlp.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_mlp(X_val)  # shape: [val_size, 1]\n",
    "    print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6db29b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.8293079137802124, 0.9014742374420166, 0.08598034083843231, 0.9043196439743042, 0.8328412771224976, 0.6396105289459229, 1.018345832824707, 1.0148504972457886, 0.07582652568817139, 1.1398913860321045, 1.0812084674835205, 0.6396105289459229, 0.6974140405654907, 0.6197280287742615, 1.012668490409851, 0.544017493724823, 0.9935578107833862, 0.4704541265964508, 0.7640637159347534, 1.021545648574829, 0.8043786287307739, 0.253126323223114, 0.30835044384002686, 0.9212926626205444, 0.8569950461387634, 0.5862722396850586, 0.7279032468795776, 0.09542017430067062, 0.96559739112854, 0.08110891282558441, 0.2542800009250641, 0.24222812056541443, 0.37486138939857483, 0.9100958108901978, 0.6760077476501465, 0.24045519530773163, 0.1667739301919937, 0.6396105289459229, 0.9678096175193787, 0.5499078631401062, 0.9968855977058411, 0.6700551509857178, 0.6002070903778076, 0.4207437038421631, 0.2873627543449402, 0.9360692501068115, 0.809744119644165, 0.9323835372924805, 1.011879801750183, 0.3565305471420288, 1.0148504972457886, 0.37746602296829224, 0.7745526432991028, 0.07467273622751236, 0.796276330947876, 0.7163875102996826, 0.30117589235305786, 0.5426048040390015, 1.096300721168518, 0.741117000579834, 0.8867450952529907, 0.6918687224388123, 0.3425338566303253, 0.08272355049848557, 0.8273677825927734, 0.6874610185623169, 0.6476293802261353, 0.9903693199157715, 1.02516770362854, 0.6576879024505615, 0.6685124635696411, 0.8544453382492065, 0.5354952812194824, 1.021545648574829, 0.4801149070262909, 0.8917934894561768, 0.8690519332885742, 0.3721688389778137, 1.0121026039123535, 0.5943633317947388, 0.8962597846984863, 0.728429913520813, 0.8328412175178528, 0.9614551067352295, 0.659273624420166, 0.24102135002613068, 0.07939063757658005]\n",
      "Ground Truth: [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", val_outputs.squeeze().tolist())\n",
    "print(\"Ground Truth:\", y_val.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0937e3",
   "metadata": {},
   "source": [
    "## References <a name=\"references\"></a>\n",
    "\n",
    "<a name=\"1\"></a> [1] Chen, L., Li, B., Chen, Y., Lin, M., Zhang, S., Li, C., Pang, Y., & Wang, L. (2024). ADCNet: A unified framework for predicting the activity of antibodyâ€‘drug conjugates. https://arxiv.org/pdf/2401.09176\n",
    "\n",
    "<a name=\"2\"></a> [2] DeepChem Team. (n.d.). Introduction to Antibody-Drug Conjugates. https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Introduction_to_ADCNet.ipynb\n",
    "\n",
    "<a name=\"3\"></a> [3] Facebook AI Research. (2020). ESM: Evolutionary Scale Modeling [GitHub repository]. https://github.com/facebookresearch/esm\n",
    "\n",
    "<a name=\"4\"></a> [4] ADCNet githubidrugLab.(2024). ADCNet: a unified framework for predicting the activity of antibodyâ€‘drug conjugates. GitHub repository: https://github.com/idrugLab/ADCNet\n",
    "\n",
    "<a name=\"5\"></a> [5] Shen, L.â€¯T., Sun, X.â€¯N., Chen, Z., Guo, Y., Shen, Z.â€¯Y., Song, Y., Xin, W.â€¯X., Ding, H.â€¯Y., Ma, X.â€¯Y., Xu, W.â€¯B., Zhou, W.â€¯Y., Che, J.â€¯X., Tan, L.â€¯L., Chen, L.â€¯S., Chen, S.â€¯Q., Dong, X.â€¯W., Fang, L., & Zhu, F. (2024).\n",
    "ADCdb: the database of antibodyâ€‘drug conjugates. Nucleic Acids Research, 52(D1), D1097â€“D1109. PMIDâ€¯37831118.\n",
    "Website: https://adcdb.idrblab.net/\n",
    "\n",
    "<a name=\"6\"></a> [6] ADCNet githubidrugLab.(2024). ADCNet: a unified framework for predicting the activity of antibodyâ€‘drug conjugates. GitHub repository: https://github.com/idrugLab/ADCNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4daf9d",
   "metadata": {},
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Gitter\n",
    "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9308f",
   "metadata": {},
   "source": [
    "# Citing this tutorial\n",
    "If you found this tutorial useful please consider citing it using the provided BibTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ceea7",
   "metadata": {},
   "source": [
    "```\n",
    "@manual{Molecular Machine Learning,\n",
    " title={Introduction to ADCNet: Predicting ADC Activity with DeepChem},\n",
    " organization={DeepChem},\n",
    " author={Patra, Sonali Lipsa and Bisoi, Ankita and Singh, Rakshit Kr. and Ramsundar, Bharath}\n",
    " howpublished = {\\url{https://github.com/deepchem/deepchem/blob/master/examples/tutorials/ADCNet.ipynb}},\n",
    " year={2025},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
