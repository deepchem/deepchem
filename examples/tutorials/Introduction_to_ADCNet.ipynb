{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6f0b77",
   "metadata": {},
   "source": [
    "## **Introduction to ADCNet: Predicting ADC Activity with DeepChem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f37d4",
   "metadata": {},
   "source": [
    "Advancements in molecular biology have significantly transformed the landscape of drug discovery, shifting the focus towards identifying more selective and promising clinical candidates. While traditional small-molecule inhibitors have achieved notable success, they are often limited by off-target toxicity, narrow therapeutic windows, and the emergence of drug resistance. The development of monoclonal antibodies (mAbs) offered a partial solution by exploiting specific antigen expression to enhance targeting accuracy. However, their effectiveness remains limited, particularly in treating heterogeneous populations of cancer cells.[[1]](#1) <br>\n",
    "\n",
    "To overcome these challenges, Antibody-Drug Conjugates or ADCs have emerged as a novel and promising therapeutic strategy. ADCs are a class of targeted biopharmaceutical drugs that are designed as targeted therapy to treat cancer. ADCs combine the specificity of monoclonal antibodies with the potent cytotoxicity of drugs, linked through specialized chemical linkers. This enables selective delivery of toxic agents to cancer cells while minimizing harm to healthy tissue, improving outcomes, and reducing side effects. However, designing effective ADCs remains complex, involving careful selection of antibodies, payloads, and linkers. These factors all impact the safety, effectiveness, and overall therapeutic success of ADCs' performance.\n",
    "\n",
    "To navigate this complexity, ADCNet has been developed as a comprehensive deep learning framework that accurately predicts the activity of antibody-drug conjugates. It combines two advanced representation models: ESM-2, which identifies important features from the protein sequences of antibodies and antigens, and FG-BERT, which processes the SMILES strings of linkers and payloads. Moreover, the framework includes the Drug-Antibody Ratio (DAR), an essential numerical parameter that influences the therapeutic index of ADCs. By learning and integrating patterns from these various molecular components, ADCNet aids in the rational design of safer and more effective ADC candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d633c53",
   "metadata": {},
   "source": [
    "In this tutorial, we will explore how to predict the therapeutic activity of Antibody-Drug Conjugates (ADCs) using ADCNet, a unified deep learning framework implemented in DeepChem. Before, proceeding with this guide, it is recommended to build a foundational understanding of ADCs. Refer to the \"Introduction to Antibody-Drug Conjugates\" [[2]](#2) notebook available in the DeepChem tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8451a",
   "metadata": {},
   "source": [
    "# **Colab**\n",
    "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Introduction_to_ADCNet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b88c1d",
   "metadata": {},
   "source": [
    "## **Evolution of ADCs**\n",
    "\n",
    "As the field continues to advance, the design of ADCs has been progressively refined over several generations. First-generation ADCs, such as *gemtuzumab ozogamicin*, were built using humanized antibodies, a single type of cytotoxic drug, and acid-sensitive linkers. These components were originally derived from murine antibodies and conventional chemotherapy agents. The conjugation process was typically random, targeting lysine or cysteine residues, which resulted in mixtures with uneven Drug-Antibody Ratios (DAR). This lack of uniformity made it difficult to establish a consistent therapeutic index and often led to off-target toxicity and narrow treatment windows. As a result, first-generation ADCs were prone to unmanageable side effects and limited clinical effectiveness.<br>\n",
    "\n",
    "In contrast, second-generation ADCs, such as *brentuximab vedotin* and *trastuzumab emtansine*, introduced more powerful cytotoxic agents like tubulin inhibitors, along with more stable linkers. These improvements significantly enhanced both the treatment’s efficacy and molecular stability.<br>\n",
    "\n",
    "Moreover, the third generation ADCs, represented by drugs like *polatuzumab vedotin* and *enfortumab vedotin*, introduced site-specific conjugation techniques and hydrophilic linkers. These innovations allowed for precise control over DAR, thereby enhancing both safety and therapeutic efficacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fbc0b",
   "metadata": {},
   "source": [
    "Now that we’ve explored the fundamentals and evolution of ADCs, let’s dive into the ADCNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb6044",
   "metadata": {},
   "source": [
    "## **Overview of the model architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36331efe",
   "metadata": {},
   "source": [
    "We have a three-step execution process: first, we process different types of input data; second, we generate embeddings from these inputs using pretrained models; and lastly, we concatenate the embeddings and feed them into a Multilayer Perceptron (MLP) to predict the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cebf7",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cd28e",
   "metadata": {},
   "source": [
    "Let's explore the three different forms of inputs we use:\n",
    "\n",
    "(I) **Protein Sequences:**\n",
    "- **Antibody Heavy Chain:** The protein sequence of the antibody's heavy chain.\n",
    "- **Antibody Light Chain:** The protein sequence of the antibody's light chain.\n",
    "- **Antigen:** The protein sequence of the target antigen.\n",
    "\n",
    "(II) **Small Molecules (SMILES representations):**\n",
    "- **Linker:** A SMILES string representing the chemical structure of the linker.\n",
    "- **Payload:** A SMILES string representing the chemical structure of the cytotoxic payload.\n",
    "\n",
    "(III) **Numerical Value:**\n",
    "- **Drug–Antibody Ratio (DAR):** A value indicating the average number of payload molecules attached to each antibody.\n",
    "\n",
    "Each input is processed separately to extract its unique features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956f172",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c21ff",
   "metadata": {},
   "source": [
    "ADCNet uses pre-trained language models to transform the inputs into embeddings:\n",
    "\n",
    "- Protein sequences (antibody heavy chain, antibody light chain, and antigen sequences) are processed using ESM-2 (Evolutionary Scale Modeling) [[3]](#3), a Transformer-based protein language model. ESM-2 converts these sequences into dense embeddings that encode their structural and functional properties.\n",
    "- SMILES representations of the linker and payload are processed using ChemBERTA, which generates embeddings that capture the chemical properties of these small molecules.\n",
    "\n",
    "(**Note**: While the original ADCNet paper utilized FGBERT, we are employing ChemBERTA here due to its availability and effectiveness within the DeepChem framework.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7347c06",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753682f",
   "metadata": {},
   "source": [
    "After generating the embeddings:\n",
    "\n",
    "- The embeddings from the three protein sequences (heavy chain, light chain, and antigen), the two small molecules (linker and payload), and the processed DAR value are concatenated into a single feature vector.\n",
    "- This combined feature vector is then fed into a Multilayer Perceptron (MLP) comprising two fully connected layers with non-linear activation functions. The MLP analyzes the concatenated features to predict the antibody-drug conjugate's therapeutic activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b7b0a",
   "metadata": {},
   "source": [
    "Below is the architecture diagram of ADCNet, illustrating the complete workflow from input sequences and molecular structures through embedding layers and model components to the final prediction output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f90a13",
   "metadata": {},
   "source": [
    "<img src=\"assets/ADCNet_2.png\" alt=\"image2\" height = \"800\" width=\"800\"> <br> **Fig.1** Diagram illustrating the network architecture of ADCNet model. [[4]](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392de31",
   "metadata": {},
   "source": [
    "### Versatility of ADCNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc056aa",
   "metadata": {},
   "source": [
    "According to the original [ADCNet paper](https://arxiv.org/pdf/2401.09176), the architecture utilizes the protein language model ESM-2 to process antibody and antigen sequences. While ESM-2 is highly effective, restricting the framework to a single model limits its adaptability to other protein representation techniques that could offer complementary strengths. Researchers can explore alternative models, such as ProtBERT, T5-Protein, or newer protein language models that are tailored to specific tasks. This flexibility allows for experimentation with models that better capture the structural and functional nuances of antibodies and antigens, depending on the context of the ADC design. For example, some models may excel at predicting binding affinity, while others may be more adept at handling sequence diversity.\n",
    "\n",
    "Similarly, the original ADCNet architecture utilizes FG-BERT for encoding linker and payload SMILES strings. Although FG-BERT is effective for small molecule representation, relying solely on it restricts the framework's ability to incorporate advancements in chemical modeling. To enhance performance, researchers can adopt other small molecule models, such as ChemBERTa, MolBERT, or various graph-based or transformer-based chemical encoders.\n",
    "\n",
    "In our implementation, we use ESM-2-8M, but researchers are encouraged to experiment with other ESM variants, such as ESM-2 650M and ESM-2-3B, which may offer improved accuracy. Additionally, we have replaced FG-BERT with ChemBERTa in this implementation to take advantage of its strengths in small molecule representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae7db8",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e30b4e",
   "metadata": {},
   "source": [
    "Before we proceed, let's install DeepChem into our environment and set up other required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975c6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepchem in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.4.2)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (2.0.3)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.13.3)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (1.10.1)\n",
      "Requirement already satisfied: rdkit in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from deepchem) (2024.3.5)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from pandas->deepchem) (2025.2)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from rdkit->deepchem) (10.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from sympy->deepchem) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/adcnet/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install the necessary libraries\n",
    "!pip install deepchem numpy torch scikit-learn transformers tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e65167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/adcnet/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66558ea9",
   "metadata": {},
   "source": [
    "### Data Collection and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b9644",
   "metadata": {},
   "source": [
    "We will be using ADCdb, which was originally utilized by ADCNet and can be accessed at [[5]](#5). This database contains information on 6,572 antibody-drug conjugates (ADCs), including 359 that are approved by the FDA or are currently in clinical trials, 501 in preclinical testing, 819 with in vivo testing data, 1,868 with cell line or target testing data, and 3,025 without such testing.\n",
    "\n",
    "For our purposes, we will use the preprocessed data for convenience, which is available at [[6]](#6). Let’s take a look at the dataset. The original ADCdb is a comprehensive collection of data on ADCs, and we will be working with the preprocessed version provided by ADCNet. This version can be found in the assets folder or in the ADCdb GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have data of 435 ADCs.\n"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "file_path = \"assets/adcdb.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f'We have data of {len(df)} ADCs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb5dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'ADC ID',\n",
       " 'ADC Name',\n",
       " 'Antibody Name',\n",
       " 'Antibody Heavy Chain Sequence',\n",
       " 'Antibody Light Chain Sequence',\n",
       " 'Antigen Sequence',\n",
       " 'Payload Isosmiles',\n",
       " 'Linker Isosmiles',\n",
       " 'DAR',\n",
       " 'label（10nm）',\n",
       " 'label（100nm）',\n",
       " 'label（1nm）',\n",
       " 'label（1000nm）',\n",
       " 'DAR_val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa112c7",
   "metadata": {},
   "source": [
    "We can see the dataset contains columns representing ADC names, antibody sequences, antigen sequences, SMILES strings for linker/payload, and labels at multiple concentrations. Now lets have a preview of the dataset we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2407728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ADC ID</th>\n",
       "      <th>ADC Name</th>\n",
       "      <th>Antibody Name</th>\n",
       "      <th>Antibody Heavy Chain Sequence</th>\n",
       "      <th>Antibody Light Chain Sequence</th>\n",
       "      <th>Antigen Sequence</th>\n",
       "      <th>Payload Isosmiles</th>\n",
       "      <th>Linker Isosmiles</th>\n",
       "      <th>DAR</th>\n",
       "      <th>label（10nm）</th>\n",
       "      <th>label（100nm）</th>\n",
       "      <th>label（1nm）</th>\n",
       "      <th>label（1000nm）</th>\n",
       "      <th>DAR_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DRG0ABJAM</td>\n",
       "      <td>Trastuzumab-BCN-HydraSpace-Val-Cit-PABC-Gly-Ca...</td>\n",
       "      <td>Trastuzumab</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>CCN(C(=O)CN)C1COC(OC2C(OC3C#C/C=C\\C#CC4(O)CC(=...</td>\n",
       "      <td>CC(C)C(NC(=O)OCCN(CCOC(=O)NC(C(=O)NC(CCCNC(N)=...</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DRG0ZBATX</td>\n",
       "      <td>Anti-KIT NEG087?SSNPP-DM3</td>\n",
       "      <td>Anti-KIT mAb NEG087</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFSDYYMAWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...</td>\n",
       "      <td>MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...</td>\n",
       "      <td>C[C@@H]1[C@@H]2C[C@]([C@@H](/C=C/C=C(/CC3=CC(=...</td>\n",
       "      <td>CC(S)CCC(N)=O</td>\n",
       "      <td>3.0-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DRG0XJKXB</td>\n",
       "      <td>Trastuzumab-C239I-SG3400</td>\n",
       "      <td>Engineered trastuzumab</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...</td>\n",
       "      <td>C=C1CC2C=Nc3cc(OCCCOc4cc5c(cc4OC)C(=O)N4CC(=C)...</td>\n",
       "      <td>C[C@@H](C(=O)NC1=CC=C(C=C1)CO)NC(=O)[C@H](C(C)...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DRG0ZOYQV</td>\n",
       "      <td>Datopotamab deruxtecan</td>\n",
       "      <td>Datopotamab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYTFTTAGMQWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCKASQDVSTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>MARGPGLAPPPLRLPLLLLVLAAVTGHTAAQDNCTCPTNKMTVCSP...</td>\n",
       "      <td>CC[C@@]1(C2=C(COC1=O)C(=O)N3CC4=C5[C@H](CCC6=C...</td>\n",
       "      <td>C1=CC=C(C=C1)C[C@@H](C(=O)NCC(=O)O)NC(=O)CNC(=...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DRG0COMTY</td>\n",
       "      <td>Telisotuzumab vedotin</td>\n",
       "      <td>Telisotuzumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKASGYIFTAYTMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTQSPDSLAVSLGERATINCKSSESVDSYANSFLHWYQQKPGQ...</td>\n",
       "      <td>MKAPAVLAPGILVLLFTLVQRSNGECKEALAKSEMNVNMKYQLPNF...</td>\n",
       "      <td>CC[C@H](C)[C@@H]([C@@H](CC(=O)N1CCC[C@H]1[C@@H...</td>\n",
       "      <td>CC(C)[C@@H](C(=O)N[C@@H](CCCNC(=O)N)C(=O)NC1=C...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     ADC ID                                           ADC Name  \\\n",
       "0      0  DRG0ABJAM  Trastuzumab-BCN-HydraSpace-Val-Cit-PABC-Gly-Ca...   \n",
       "1      1  DRG0ZBATX                          Anti-KIT NEG087?SSNPP-DM3   \n",
       "2      2  DRG0XJKXB                           Trastuzumab-C239I-SG3400   \n",
       "3      3  DRG0ZOYQV                             Datopotamab deruxtecan   \n",
       "4      4  DRG0COMTY                              Telisotuzumab vedotin   \n",
       "\n",
       "            Antibody Name                      Antibody Heavy Chain Sequence  \\\n",
       "0             Trastuzumab  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "1     Anti-KIT mAb NEG087  EVQLVESGGGLVQPGGSLRLSCAASGFTFSDYYMAWVRQAPGKGLE...   \n",
       "2  Engineered trastuzumab  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "3             Datopotamab  QVQLVQSGAEVKKPGASVKVSCKASGYTFTTAGMQWVRQAPGQGLE...   \n",
       "4           Telisotuzumab  QVQLVQSGAEVKKPGASVKVSCKASGYIFTAYTMHWVRQAPGQGLE...   \n",
       "\n",
       "                       Antibody Light Chain Sequence  \\\n",
       "0  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKL...   \n",
       "2  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "3  DIQMTQSPSSLSASVGDRVTITCKASQDVSTAVAWYQQKPGKAPKL...   \n",
       "4  DIVMTQSPDSLAVSLGERATINCKSSESVDSYANSFLHWYQQKPGQ...   \n",
       "\n",
       "                                    Antigen Sequence  \\\n",
       "0  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...   \n",
       "1  MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...   \n",
       "2  MELAALCRWGLLLALLPPGAASTQVCTGTDMKLRLPASPETHLDML...   \n",
       "3  MARGPGLAPPPLRLPLLLLVLAAVTGHTAAQDNCTCPTNKMTVCSP...   \n",
       "4  MKAPAVLAPGILVLLFTLVQRSNGECKEALAKSEMNVNMKYQLPNF...   \n",
       "\n",
       "                                   Payload Isosmiles  \\\n",
       "0  CCN(C(=O)CN)C1COC(OC2C(OC3C#C/C=C\\C#CC4(O)CC(=...   \n",
       "1  C[C@@H]1[C@@H]2C[C@]([C@@H](/C=C/C=C(/CC3=CC(=...   \n",
       "2  C=C1CC2C=Nc3cc(OCCCOc4cc5c(cc4OC)C(=O)N4CC(=C)...   \n",
       "3  CC[C@@]1(C2=C(COC1=O)C(=O)N3CC4=C5[C@H](CCC6=C...   \n",
       "4  CC[C@H](C)[C@@H]([C@@H](CC(=O)N1CCC[C@H]1[C@@H...   \n",
       "\n",
       "                                    Linker Isosmiles      DAR  label（10nm）  \\\n",
       "0  CC(C)C(NC(=O)OCCN(CCOC(=O)NC(C(=O)NC(CCCNC(N)=...     1.86            0   \n",
       "1                                      CC(S)CCC(N)=O  3.0-4.0            0   \n",
       "2  C[C@@H](C(=O)NC1=CC=C(C=C1)CO)NC(=O)[C@H](C(C)...     1.71            1   \n",
       "3  C1=CC=C(C=C1)C[C@@H](C(=O)NCC(=O)O)NC(=O)CNC(=...        4            1   \n",
       "4  CC(C)[C@@H](C(=O)N[C@@H](CCCNC(=O)N)C(=O)NC1=C...      3.1            1   \n",
       "\n",
       "   label（100nm）  label（1nm）  label（1000nm）  DAR_val  \n",
       "0             0           0              0     1.86  \n",
       "1             0           0              0     3.50  \n",
       "2             1           1              1     1.71  \n",
       "3             1           1              1     4.00  \n",
       "4             1           1              1     3.10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81af8ce",
   "metadata": {},
   "source": [
    "### Preprocessing Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e258e4",
   "metadata": {},
   "source": [
    "We can see that the dataset includes an important feature: the Drug-Antibody Ratio (DAR), which plays a significant role in determining the efficacy and safety of ADCs, as it represents the average number of drug molecules attached to each antibody. Since DAR is a continuous numerical feature, we will scale it before inputting it into our model. Standardizing DAR to have zero mean and unit variance ensures that it is on a comparable scale with other features, which helps neural networks train more efficiently and converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract and scale the Drug-Antibody Ratio (DAR)\n",
    "\n",
    "dar_values = df['DAR_val'].values.reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "dar_scaled = scaler.fit_transform(dar_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db011b3",
   "metadata": {},
   "source": [
    "Let's preview the first five scaled DAR values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23159543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28000061],\n",
       "       [-0.2348211 ],\n",
       "       [-1.3755963 ],\n",
       "       [ 0.08383119],\n",
       "       [-0.48974293]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301eccb1",
   "metadata": {},
   "source": [
    "Now that our data is preprocessed and the Drug–Antibody Ratio (DAR) values are standardized, we are ready to generate embeddings using pre-trained models for each input type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4005443",
   "metadata": {},
   "source": [
    "### Generating Embeddings with Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32ef4c",
   "metadata": {},
   "source": [
    "Set up the computation device (GPU if available, otherwise CPU) and import necessary transformer modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e972aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EsmTokenizer, EsmModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Choose device\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e91703",
   "metadata": {},
   "source": [
    "Before we move further, it's necessary to know about ESM-2. ESM-2 (Evolutionary Scale Modeling) is a protein language model using a transformer-based architecture to process protein sequences. It has been trained on large datasets of protein sequences to learn the relationships between amino acids and the structural and functional properties of proteins.\n",
    "\n",
    "ESM-2 has demonstrated strong performance across various protein-related prediction tasks, making it a reliable choice for encoding protein sequences in deep learning workflows. To explore ESM-2 and other protein language models developed by Meta’s FAIR (Fundamental AI Research) team, visit the official GitHub repository [here](https://github.com/facebookresearch/esm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c28b9c",
   "metadata": {},
   "source": [
    "Here we use the smallest ESM-2 model (esm2_t6_8M_UR50D, 6 layers, 8M parameters) for protein sequence embeddings. Larger ESM-2 models are available in the [Hugging Face Model Hub](https://huggingface.co/facebook/esm2_t6_8M_UR50D) for improved accuracy at the cost of increased computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d96a422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load ESM-2 for protein sequences\n",
    "esm_model_name = \"facebook/esm2_t6_8M_UR50D\"\n",
    "tokenizer_esm = AutoTokenizer.from_pretrained(esm_model_name)\n",
    "esm_model = AutoModel.from_pretrained(esm_model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2f8fe",
   "metadata": {},
   "source": [
    "For small molecules like payloads and linkers, we will use ChemBERTa to generate embeddings from the SMILES strings of payloads and linkers. ChemBERTa is a Transformer-based model pre-trained on chemical SMILES, enabling it to capture the structural and chemical properties of small molecules for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec374ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ChemBERTa (for payload & linker)\n",
    "chemberta_model_name = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "chemberta_tokenizer = AutoTokenizer.from_pretrained(chemberta_model_name)\n",
    "chemberta_model = AutoModel.from_pretrained(chemberta_model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c9100",
   "metadata": {},
   "source": [
    "Now we have initialized two Transformer-based models: ESM-2 for protein sequences, and ChemBERTa for SMILES. Loading them onto the computation device allows fast embedding extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3decf",
   "metadata": {},
   "source": [
    "We will now generate embeddings for the antibody heavy chain, light chain, and antigen protein sequences in our dataset using ESM-2. These embeddings capture the structural and functional properties of each protein sequence, enabling the model to learn meaningful biological representations for downstream prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcf5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequences and SMILES from the dataframe\n",
    "\n",
    "heavy_chains = df['Antibody Heavy Chain Sequence'].astype(str).tolist()\n",
    "light_chains = df['Antibody Light Chain Sequence'].astype(str).tolist()\n",
    "antigens = df['Antigen Sequence'].astype(str).tolist()\n",
    "linkers = df['Linker Isosmiles'].tolist()\n",
    "payloads = df['Payload Isosmiles'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd177348",
   "metadata": {},
   "source": [
    "Let's first generate embeddings from protein sequences using ESM-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67dd7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1000\n",
    "\n",
    "# Function to get embeddings from protein sequences\n",
    "def get_embeddings(sequences):\n",
    "    embeddings = []\n",
    "\n",
    "    for seq in tqdm(sequences, desc=\"Generating embeddings\"):\n",
    "        inputs = tokenizer_esm(\n",
    "            seq,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            is_split_into_words=False\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = esm_model(**inputs)\n",
    "        \n",
    "        # Extract CLS token\n",
    "        cls_emb = outputs.last_hidden_state[:, 0, :].squeeze().cpu()\n",
    "        embeddings.append(cls_emb)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750d918",
   "metadata": {},
   "source": [
    "Now we can use the above function to generate embeddings for our protein sequences (heavy chains, light chains, and antigens) by passing the corresponding sequence lists as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69770e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings from protein sequences\n",
    "# print(\"Generating embeddings for heavy chains, light chains, and antigens...\")\n",
    "\n",
    "# heavy_embeddings = get_embeddings(heavy_chains)\n",
    "# light_embeddings = get_embeddings(light_chains)\n",
    "# antigen_embeddings = get_embeddings(antigens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a85b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Save each tensor\n",
    "# torch.save(heavy_embeddings, 'heavy_embeddings.pt')\n",
    "# torch.save(light_embeddings, 'light_embeddings.pt')\n",
    "# torch.save(antigen_embeddings, 'antigen_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f76b24a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hk/49v0ss1d0cd6830pjsfgbg440000gn/T/ipykernel_12462/1050818796.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  heavy_embeddings = torch.load('heavy_embeddings.pt')\n",
      "/var/folders/hk/49v0ss1d0cd6830pjsfgbg440000gn/T/ipykernel_12462/1050818796.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  light_embeddings = torch.load('light_embeddings.pt')\n",
      "/var/folders/hk/49v0ss1d0cd6830pjsfgbg440000gn/T/ipykernel_12462/1050818796.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  antigen_embeddings = torch.load('antigen_embeddings.pt')\n"
     ]
    }
   ],
   "source": [
    "# Load each tensor separately\n",
    "heavy_embeddings = torch.load('heavy_embeddings.pt')\n",
    "light_embeddings = torch.load('light_embeddings.pt')\n",
    "antigen_embeddings = torch.load('antigen_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19cde5",
   "metadata": {},
   "source": [
    "Now let's generate embeddings for the payload and linker SMILES strings using ChemBERTa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d4037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embedding for a single SMILES string\n",
    "def get_smiles_embedding(smiles: str):\n",
    "    inputs = chemberta_tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = chemberta_model(**inputs)\n",
    "        # Use the CLS token representation (first token)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]  # shape: (1, hidden_size)\n",
    "        return embedding.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f61b8",
   "metadata": {},
   "source": [
    "The above function now can be used to generate a ChemBERTa embedding for a single SMILES string, which can be used for both linker and payload molecules. <br>Lets see taking an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b206a6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCN(C(=O)CN)C1COC(OC2C(OC3C#C/C=C\\C#CC4(O)CC(=O)C(NC(=O)OC)=C3/C4=C\\CSSC(C)(C)CC(=O)NCCOCCOC)OC(C)C(NOC3CC(O)C(SC(=O)c4c(C)c(I)c(OC5OC(C)C(O)C(OC)C5O)c(OC)c4OC)C(C)O3)C2O)CC1OC\n"
     ]
    }
   ],
   "source": [
    "example = payloads[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f694572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape for example payload: (768,)\n"
     ]
    }
   ],
   "source": [
    "example_embedding = get_smiles_embedding(example)\n",
    "print(f\"Embedding shape for example payload: {example_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7345314",
   "metadata": {},
   "source": [
    "Now that we understand how to generate embeddings from SMILES strings, let's create embeddings for all linker and payload molecules in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef64263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for a list of SMILES\n",
    "\n",
    "def generate_embeddings(smiles_list):\n",
    "    \"\"\"Generate embeddings for a list of SMILES strings.\"\"\"\n",
    "    embeddings = []\n",
    "    for smi in tqdm(smiles_list):\n",
    "        try:\n",
    "            emb = get_smiles_embedding(smi)\n",
    "            embeddings.append(emb)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for {smi}: {e}\")\n",
    "            embeddings.append(None)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a49ec",
   "metadata": {},
   "source": [
    "As we have defined the function above, we can now pass our Payload SMILES string to generate embeddings. This process transforms each payload molecule into a numerical vector representation that captures its chemical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4679ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 435/435 [00:09<00:00, 44.13it/s]\n"
     ]
    }
   ],
   "source": [
    "payload_embeddings = generate_embeddings(payloads) # embeddings from payload smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea3716",
   "metadata": {},
   "source": [
    "Similarly, we can get embeddings from linker smiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c902acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:06<00:00, 65.60it/s]\n"
     ]
    }
   ],
   "source": [
    "linker_embeddings = generate_embeddings(linkers) # embeddings from linker smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a0941",
   "metadata": {},
   "source": [
    "Now that we’ve generated embeddings from all protein sequences, as well as the payload and linker SMILES, we can concatenate them, along with the standardized DAR value to form a complete feature vector for each ADC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9665ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "adc_embeddings = []\n",
    "\n",
    "num_adcs = len(heavy_embeddings)\n",
    "\n",
    "for i in range(num_adcs):\n",
    "    heavy = heavy_embeddings[i]\n",
    "    light = light_embeddings[i]\n",
    "    antigen = antigen_embeddings[i]\n",
    "    payload = payload_embeddings[i]\n",
    "    linker = linker_embeddings[i]\n",
    "    dar = dar_scaled[i]\n",
    "\n",
    "    # Convert to tensor and ensure 1D\n",
    "    for name, emb in zip(['heavy', 'light', 'antigen', 'dar'], [heavy, light, antigen, dar]):\n",
    "        if not isinstance(emb, torch.Tensor):\n",
    "            emb = torch.tensor(emb, dtype=torch.float32)\n",
    "        if emb.dim() == 0:\n",
    "            emb = emb.unsqueeze(0)\n",
    "        elif emb.dim() > 1:\n",
    "            emb = emb.squeeze()\n",
    "        locals()[name] = emb\n",
    "\n",
    "    for name, emb in zip(['payload', 'linker'], [payload, linker]):\n",
    "        if not isinstance(emb, torch.Tensor):\n",
    "            emb = torch.tensor(emb, dtype=torch.float32)\n",
    "        if emb.dim() == 0:\n",
    "            emb = emb.unsqueeze(0)\n",
    "        elif emb.dim() > 1:\n",
    "            emb = emb.squeeze()\n",
    "        locals()[name] = emb\n",
    "\n",
    "    # Concatenate all embeddings\n",
    "    full_emb = torch.cat([\n",
    "        heavy,\n",
    "        light,\n",
    "        antigen,\n",
    "        payload,\n",
    "        linker,\n",
    "        dar\n",
    "    ])  # shape: [combined_dim]\n",
    "\n",
    "    adc_embeddings.append(full_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408206f",
   "metadata": {},
   "source": [
    "Now, lets check the embedding shape of each input we have generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f92bbf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload shape: (768,)\n",
      "Linker shape: (768,)\n",
      "Heavy shape: torch.Size([320])\n",
      "Light shape: torch.Size([320])\n",
      "Antigen shape: torch.Size([320])\n",
      "DAR shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Payload shape:\", payload_embeddings[0].shape)\n",
    "print(\"Linker shape:\", linker_embeddings[0].shape)\n",
    "print(\"Heavy shape:\", heavy_embeddings[0].shape)\n",
    "print(\"Light shape:\", light_embeddings[0].shape)\n",
    "print(\"Antigen shape:\", antigen_embeddings[0].shape)\n",
    "print(\"DAR shape:\", dar_scaled[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde5900",
   "metadata": {},
   "source": [
    "Lets see the shape of a single concatenated ADC embedding i.e., feature vector for one ADC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deebda13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2497])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab78407",
   "metadata": {},
   "source": [
    "Now, we can check the shape of the full batch tensor (i.e., all ADCs stacked), where the first dimension is the number of ADCs and the second is the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10e48436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([435, 2497])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adc_batch_tensor = torch.stack(adc_embeddings)\n",
    "adc_batch_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d2b4b",
   "metadata": {},
   "source": [
    "#### Defining MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010f58c",
   "metadata": {},
   "source": [
    "Before we move into model training, it’s important to understand the architecture of the MLP (Multi-Layer Perceptron). MLP is a type of feedforward neural network consisting of an input layer, one or more hidden layers, and an output layer. Each neuron in a layer is fully connected to every neuron in the next, allowing the model to learn complex, non-linear patterns from the data.  Other inputs include Dropout and Activation function. Dropout randomly disables a fraction of neurons during each training iteration, which forces the network to not rely too heavily on any one neuron and helps in learning more robust features, and activation function is used to specify the activation function used in the hidden layers of the model. <br>\n",
    "\n",
    "In our setup, the input layer has a dimension of 2497, which corresponds to the size of the combined embeddings. This is followed by 2 hidden layers that help the model extract deeper hierarchical features, and finally, an output layer that produces predictions. Other inputs includes a dropout rate of 0.2 and Relu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5720cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/opt/miniconda3/envs/adcnet/lib/python3.8/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([435, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from deepchem.models.torch_models.layers import MultilayerPerceptron\n",
    "\n",
    "# Define the model\n",
    "ADCNet = MultilayerPerceptron(\n",
    "    d_input= 2497,\n",
    "    d_output=1,\n",
    "    d_hidden=(1024, 256),\n",
    "    dropout=0.2,\n",
    "    activation_fn='relu'\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "op = ADCNet(adc_batch_tensor)\n",
    "print(op.shape)  # [435, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ec8df",
   "metadata": {},
   "source": [
    "We will be using the 100 nm label from the dataset as our target variable. Although the dataset also includes labels at 10 nm and 1000 nm, we choose the 100 nm label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "333738c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract the label\n",
    "label_col = \"label（100nm）\"\n",
    "labels = df[label_col].values  # 0 or 1\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "y = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a0d5a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 435 samples.\n",
      "Features shape: (435, 2497), Labels shape: (435,)\n",
      "First sample features: [-0.20455705  0.8342899   0.15026727 ... -0.15449478  0.31129766\n",
      " -1.2800006 ], First sample label: 0\n"
     ]
    }
   ],
   "source": [
    "from deepchem.data.datasets import NumpyDataset\n",
    "import numpy as np\n",
    "\n",
    "X = adc_batch_tensor.numpy()  # Convert to numpy array\n",
    "y = labels\n",
    "\n",
    "dataset = NumpyDataset(X= X, y= y, ids= np.arange(len(y)))\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples.\")\n",
    "print(f\"Features shape: {dataset.X.shape}, Labels shape: {dataset.y.shape}\")\n",
    "print(f\"First sample features: {dataset.X[0]}, First sample label: {dataset.y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a811793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deepchem.data.datasets.NumpyDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfcbbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "\n",
    "# Creating a RandomSplitter object\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "\n",
    "# Splitting dataset into train and test datasets\n",
    "train_dataset, test_dataset = splitter.train_test_split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afecd59",
   "metadata": {},
   "source": [
    "Let's define the model, loss function, and optimizer that we'll be using for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "173fad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "from deepchem.models.optimizers import Adam\n",
    "\n",
    "model_name = ADCNet\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f15ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.torch_models.torch_model import TorchModel\n",
    "from deepchem.models.torch_models.layers import MultilayerPerceptron\n",
    "from deepchem.models.losses import L2Loss\n",
    "\n",
    "class ADCNetModel(TorchModel):\n",
    "    def __init__(self,input_dim=2497, output_dim=1, hidden_dims=(1024, 256), dropout=0.2, activation_fn='relu', **kwargs):\n",
    "        \n",
    "        model = MultilayerPerceptron(\n",
    "            d_input=input_dim,\n",
    "            d_output=output_dim,\n",
    "            d_hidden=hidden_dims,\n",
    "            dropout=dropout,\n",
    "            activation_fn=activation_fn\n",
    "        )\n",
    "        super(ADCNetModel, self).__init__(model = model, loss = L2Loss(), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32bdd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = ADCNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede071af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c68a48",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213046b",
   "metadata": {},
   "source": [
    "We'll train the model on the training set and evaluate its performance on the validation set across multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82399bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we define two lists to store the training and validation loss values after each epoch.\n",
    "\n",
    "train_losses = []\n",
    "val_losses = [] \n",
    "\n",
    "# Training Loop\n",
    "\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model_mlp.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     outputs = mode(X_train)\n",
    "#     loss = criterion(outputs, y_train)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     model_mlp.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_outputs = model_mlp(X_val)\n",
    "#         val_loss = criterion(val_outputs, y_val)\n",
    "\n",
    "#     train_losses.append(loss.item())\n",
    "#     val_losses.append(val_loss.item())\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f\"Epoch {epoch} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ac333",
   "metadata": {},
   "source": [
    "As shown above, we can see the training and validation loss over epochs, notice that we have a high training loss at early stage of training the model. But the training loss and validation loss are decreasing over time, which implies the model is generalizing well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784aa10",
   "metadata": {},
   "source": [
    "Let's check out the first 5 predictions from the MLP model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_mlp(X_val)\n",
    "    print(preds[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a3f99",
   "metadata": {},
   "source": [
    "So, now lets check, our predicted values with our actual labels, to get insights how well the model is performing, and gain insights into the prediction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db29b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions:\", val_outputs.squeeze().tolist())\n",
    "print(\"Ground Truth:\", y_val.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7030779",
   "metadata": {},
   "source": [
    "Finally, let's plot the loss curve to get better insights on our training and validation loss over epochs. So, visualizing the training and validation loss curves is necessary and helps us understand how well the model is learning over time. A steadily decreasing training loss indicates that the model is fitting the data, while the validation loss provides insight into how well the model generalizes to unseen data. If the validation loss starts increasing while the training loss continues to decrease, it may indicate overfitting. By examining these curves, we can diagnose issues such as underfitting, overfitting, or the need for further hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa530e5",
   "metadata": {},
   "source": [
    "It's time to check the accuracy of our model. So, accuracy is measured as the proportion of correct predictions (where the predicted label matches the true label) out of the total number of samples in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab6701",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels = torch.round(val_outputs.squeeze())  # round to 0 or 1\n",
    "true_labels = y_val.squeeze()\n",
    "\n",
    "\n",
    "correct = (predicted_labels == true_labels).sum().item()\n",
    "total = true_labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800519e2",
   "metadata": {},
   "source": [
    "So, we achieved a validation accuracy of 82.76%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0937e3",
   "metadata": {},
   "source": [
    "## References <a name=\"references\"></a>\n",
    "\n",
    "<a name=\"1\"></a> [1] Chen, L., Li, B., Chen, Y., Lin, M., Zhang, S., Li, C., Pang, Y., & Wang, L. (2024). ADCNet: A unified framework for predicting the activity of antibody‑drug conjugates. https://arxiv.org/pdf/2401.09176\n",
    "\n",
    "<a name=\"2\"></a> [2] DeepChem Team. (n.d.). Introduction to Antibody-Drug Conjugates. https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Introduction_to_Antibody_Drug_Conjugates.ipynb\n",
    "\n",
    "<a name=\"3\"></a> [3] Facebook AI Research. (2020). ESM: Evolutionary Scale Modeling [GitHub repository]. https://github.com/facebookresearch/esm\n",
    "\n",
    "<a name=\"4\"></a> [4] ADCNet githubidrugLab.(2024). ADCNet: a unified framework for predicting the activity of antibody‑drug conjugates. GitHub repository: https://github.com/idrugLab/ADCNet\n",
    "\n",
    "<a name=\"5\"></a> [5] Shen, L. T., Sun, X. N., Chen, Z., Guo, Y., Shen, Z. Y., Song, Y., Xin, W. X., Ding, H. Y., Ma, X. Y., Xu, W. B., Zhou, W. Y., Che, J. X., Tan, L. L., Chen, L. S., Chen, S. Q., Dong, X. W., Fang, L., & Zhu, F. (2024).\n",
    "ADCdb: the database of antibody‑drug conjugates. Nucleic Acids Research, 52(D1), D1097–D1109. PMID 37831118.\n",
    "Website: https://adcdb.idrblab.net/\n",
    "\n",
    "<a name=\"6\"></a> [6] ADCNet githubidrugLab.(2024). ADCNet: a unified framework for predicting the activity of antibody‑drug conjugates. GitHub repository: https://github.com/idrugLab/ADCNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4daf9d",
   "metadata": {},
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Discord\n",
    "The DeepChem [Discord](https://discord.gg/5d5bEVSt) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9308f",
   "metadata": {},
   "source": [
    "# Citing this tutorial\n",
    "If you found this tutorial useful please consider citing it using the provided BibTeX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ceea7",
   "metadata": {},
   "source": [
    "```\n",
    "@manual{Molecular Machine Learning,\n",
    " title={Introduction to ADCNet: Predicting ADC Activity with DeepChem},\n",
    " organization={DeepChem},\n",
    " author={Patra, Sonali Lipsa, and Singh, Rakshit Kr. and Bisoi, Ankita and Ramsundar, Bharath}\n",
    " howpublished = {\\url{https://github.com/deepchem/deepchem/blob/master/examples/tutorials/ADCNet.ipynb}},\n",
    " year={2025},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
