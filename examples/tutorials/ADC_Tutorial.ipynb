{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJXQvauyvs8"
      },
      "source": [
        "\n",
        "# **Antibody Drug Conjugate Tutorial**\n",
        "Author : [Viren Loka](https://github.com/VirenLoka)\n",
        "\n",
        "This tutorial is designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1An5DlWOL7SiJ4u6rFcUeD9rlONM6ralI?usp=sharing)\n",
        "# **What is an Antibody-Drug Conjugate?**  \n",
        "\n",
        "**Antibody-Drug Conjugates (ADCs)** are a class of targeted cancer therapies. They combine the target specificity of monoclonal antibodies with the cytotoxic potency of small-molecule drugs, offering a highly selective approach to destroying cancer cells while minimizing damage to healthy tissues.  \n",
        "\n",
        "They are molecules consisting of:  \n",
        "\n",
        "### **1. Monoclonal Antibodies (mAb):**  \n",
        "- Laboratory-produced proteins that are used to target/bind to specific antigen proteins on the surface of cancer cells.  \n",
        "\n",
        "### **2. Linker:**  \n",
        "- A chemical structure that connects the antibody to the drug.  \n",
        "- The linker must meet several requirements beyond just binding the antibody, which will be explored later.  \n",
        "\n",
        "### **3. Drug (Payload):**  \n",
        "- A highly potent cytotoxic agent designed to kill cancer cells.  \n",
        "\n",
        "Antibody-drug conjugates become a very effective combination when you consider the **high specificity** of a monoclonal antibody and the **potent cytotoxicity** of a drug payload.  \n",
        "\n",
        "![Structure of ADC](assets/ADC_Structure.png)  \n",
        "Image Credit: https://www.urotoday.com/\n",
        "\n",
        "---\n",
        "\n",
        "# **Structure of Antibody**  \n",
        "\n",
        "Antibodies (Abs) are typically represented as **Y-shaped proteins** that bind to their cognate epitope surfaces with **high specificity and affinity**.  \n",
        "\n",
        "### **Key Structural Features:**  \n",
        "- **Composed of:**  \n",
        "  - Two identical **light chains**  \n",
        "  - Two identical **heavy chains**  \n",
        "  - Linked by **disulfide bonds**  \n",
        "- **Antigen-binding site:**  \n",
        "  - Formed by the **variable regions**  \n",
        "  - Contains **hypervariable loops** known as **complementarity-determining regions (CDRs)**  \n",
        "  - CDRs dictate **specificity and affinity** of the antibody-antigen interaction  \n",
        "\n",
        "![Antibody Structure](assets/AntiBody_Structure.png)  \n",
        "Image Credit:  https://www.dianova.com/\n",
        "\n",
        "---\n",
        "\n",
        "# **Working Mechanism of an Antibody-Drug Conjugate**  \n",
        "\n",
        "The working of an ADC can be illustrated in **five key steps**:  \n",
        "\n",
        "### **1. Target Recognition**  \n",
        "- The **monoclonal antibody (mAb)** component of the ADC specifically recognizes and binds to **antigens** (usually proteins) expressed on the surface of target cells, often **cancer cells**.  \n",
        "- The antibody ensures high specificity by only binding to cells that express the **target antigen**.  \n",
        "\n",
        "### **2. Endocytosis of ADC-Antigen Complex**  \n",
        "- After binding to the **cell surface antigen**, the **ADC-antigen complex** undergoes **receptor-mediated endocytosis**.  \n",
        "- **Endocytosis** is the process by which a cell takes in substances from its surroundings by enclosing them in a portion of its plasma membrane.  \n",
        "- This internalizes the complex into the cell, forming an **early endosome**, which transports it deeper inside the cell.  \n",
        "- This step allows the drug to enter the cell in a **controlled and selective** manner.  \n",
        "\n",
        "### **3. Antigen Recovery and Trafficking**  \n",
        "- The endosome **matures** and traffics the ADC-antigen complex toward the **lysosome**.  \n",
        "- During this process:  \n",
        "  - The antigen may be **recycled back** to the **cell membrane**  \n",
        "  - Or it may be **degraded**  \n",
        "  - Meanwhile, the ADC itself is processed further inside the cell.  \n",
        "\n",
        "### **4. Lysosomal Degradation**  \n",
        "- Within the **lysosome**, the **acidic environment** and **proteolytic enzymes** break down the antibody component of the ADC.  \n",
        "- This degradation releases the **cytotoxic payload**, often a highly potent chemotherapeutic agent, which is conjugated to the antibody via a **linker**.  \n",
        "\n",
        "### **5. Release of Payload and Cell Death**  \n",
        "- Once released, the **cytotoxic drug molecules** (depicted as **red stars** in the image) diffuse into the **cytoplasm** and/or **nucleus**.  \n",
        "- The **disruption of these processes** triggers the **death of the target cancer cell**.  \n",
        "\n",
        "![ADC Mechanism](assets/ADC_Flow.png)\n",
        "Image Credits: https://arxiv.org/pdf/2401.0917\n",
        "\n",
        "---\n",
        "\n",
        "# **Role of Payload Toxicity in ADCs**  \n",
        "\n",
        "- **Payload toxicity** is a **critical factor** in the design and effectiveness of **Antibody-Drug Conjugates (ADCs)**.  \n",
        "- Since only a **small amount of payload** can be delivered to a cancer cell, its **toxicity is highly important**.  \n",
        "- However, this extreme potency also raises the risk of **off-target toxicity** if the payload is released prematurely or if the antibody binds to non-cancerous tissues.  \n",
        "\n",
        "### **Key Considerations for Payload Toxicity:**  \n",
        "✔ **Potency is essential, but uncontrolled toxicity can be dangerous.**  \n",
        "✔ **Unstable linkers** or **non-specific antibodies** can cause payload release into **healthy tissues**, leading to:  \n",
        "  - **Off-target toxicity**  \n",
        "  - **Adverse side effects**  \n",
        "✔ Payload toxicity must be **potent enough to kill cancer cells** but **controlled** through:  \n",
        "  - **Stable linkers**  \n",
        "  - **Highly specific antibodies**  \n",
        "✔ **Excessive toxicity** may prevent delivering enough ADC to kill the tumor effectively.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**  \n",
        "Antibody-Drug Conjugates (ADCs) offer a powerful **targeted therapy approach** for cancer treatment by combining the specificity of **monoclonal antibodies** with the **cytotoxic potency** of small-molecule drugs. However, careful design considerations—such as **stable linkers**, **specific antibodies**, and **controlled toxicity**—are necessary to maximize their effectiveness and safety.  \n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "##SETUP\n",
        "To run DeepCHem within Colab, you'll need to run the following cell of installation commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I678haDE_Zd",
        "outputId": "5aed746e-83e3-48d0-c643-0fb89ecf7b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from deepchem) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.14.1)\n",
            "Collecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit->deepchem) (11.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepchem) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\n",
            "Downloading deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit, deepchem\n",
            "Successfully installed deepchem-2.8.0 rdkit-2024.9.6\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxbVfy4R8VD_"
      },
      "source": [
        "Import the packages you'll need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2IdqxizFDIZ"
      },
      "outputs": [],
      "source": [
        "import deepchem as dc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The below cell will download the ADC related database from dropbox, containing the input features and output, and will be stored in your directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget \"https://www.dropbox.com/scl/fi/bi5tcl05i5waih8loloar/ADCDB.xlsx?rlkey=kxzdsjnoxv01auz3afzwddcju&dl=1\" -O ADCDB.xlsx\n",
        "!wget \"https://www.dropbox.com/scl/fi/gsoqheepmce1t3wx4esxx/Antigen.pkl?rlkey=xkequ6khj7zuoc4sgjydgnkzy&st=g4npi065&dl=1\" -O Antigen.pkl\n",
        "!wget \"https://www.dropbox.com/scl/fi/z5hm5975jpmdq6oyfikl9/Heavy.pkl?rlkey=7co5qvugzpm3bol4ivgck2vrz&st=3lhpy6qn&dl=1\" -O Heavy.pkl\n",
        "!wget \"https://www.dropbox.com/scl/fi/juyc5pmaetgfiqaysi910/Light.pkl?rlkey=mecvvdwtf7145k5vu9z9n8523&st=v18ldzsp&dl=1\" -O Light.pkl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-KDaIe58bID"
      },
      "source": [
        "Download and extract the xlsx file from the link and conver it into a panda DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Usm7mBMFVmt"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('ADCDB.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9onJWtV98usj"
      },
      "source": [
        "Check the columns of the dataframe and print first five rows to get a preview.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghpFrJ-mF3Sv",
        "outputId": "75cf7fce-1354-427b-9dac-c3649b857435"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['index', 'ADC ID', 'ADC Name', 'Antibody Name',\n",
              "       'Antibody Heavy Chain Sequence', 'Antibody Light Chain Sequence',\n",
              "       'Antigen Sequence', 'Payload Isosmiles', 'Linker Isosmiles', 'DAR',\n",
              "       'label（10nm）', 'label（100nm）', 'label（1nm）', 'label（1000nm）',\n",
              "       'DAR_val'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lt-wD3e85T0"
      },
      "source": [
        "Access the columns from the dataframe which we will need as inputs and convert them into numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJqEI6qlFPCu"
      },
      "outputs": [],
      "source": [
        "sml_list1 = df[\"Payload Isosmiles\"].to_numpy()\n",
        "sml_list2 = df[\"Linker Isosmiles\"].to_numpy()\n",
        "t1 = df[\"Antibody Heavy Chain Sequence\"].to_numpy()\n",
        "t2 = df[\"Antibody Light Chain Sequence\"].to_numpy()\n",
        "t3 = df[\"Antigen Sequence\"].to_numpy()\n",
        "t4 = df[\"DAR_val\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HymA0BdGUwV",
        "outputId": "d94b6845-0b03-4bec-9e76-b2562a304009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(435,) (435,) (435,) (435,) (435,) (435,)\n"
          ]
        }
      ],
      "source": [
        "print(sml_list1.shape, sml_list2.shape, t1.shape, t2.shape, t3.shape, t4.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLDFLTx9yeb"
      },
      "source": [
        "## **Custom Artificial Neural Network (ANN) Model**\n",
        "\n",
        "This **CustomANN** model is a simple **feedforward neural network (FNN)** built using PyTorch. It is designed to process **(40, 1280)** shaped input tensors and generate a **40-dimensional output vector**.\n",
        "\n",
        "### **Model Architecture**\n",
        "- **Input Shape:** `(40, 1280)`  \n",
        "- **Flattening Layer:**  \n",
        "  - The input tensor is reshaped into a **1D vector of size 51200 (40 × 1280)** for processing.  \n",
        "- **Fully Connected Layers:**  \n",
        "  - `fc1`: First dense layer (**51200 → 512**)  \n",
        "  - **ReLU Activation** is applied for non-linearity.  \n",
        "  - `fc2`: Second dense layer (**512 → 40**)  \n",
        "- **Output Activation:**  \n",
        "  - A **Sigmoid function** normalizes the final output values between **0 and 1**.  \n",
        "- **Averaging Operation:**  \n",
        "  - The final output is **averaged across the batch dimension** using `x.mean(dim=0)`, producing a **single 40-dimensional output vector**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSBLy1HZGZ6w"
      },
      "outputs": [],
      "source": [
        "class CustomANN(nn.Module):\n",
        "    def __init__(self, input_size=(40, 1280), hidden_size=512, output_size=40):\n",
        "        super(CustomANN, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(40 * 1280, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x.mean(dim=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krQy3kJ5-J0L"
      },
      "source": [
        "## **cover_dict: Convert Pickle Dictionary to PyTorch Tensors**\n",
        "\n",
        "The `cover_dict` function processes a **pickle file containing a dictionary**, converts its values into **PyTorch tensors**, and reassigns numerical indices as new keys.\n",
        "\n",
        "### **Function Overview**\n",
        "- **Loads a Pickle File:** Reads a serialized dictionary from the specified `path`.\n",
        "- **Converts Values to PyTorch Tensors:** Ensures compatibility with PyTorch-based operations.\n",
        "- **Reassigns Keys:** The original dictionary keys are replaced with **sequential integer indices**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sobp3ZF0fmO-"
      },
      "outputs": [],
      "source": [
        "def cover_dict(path):\n",
        "    file_path = path\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "    tensor_dict = {key: torch.tensor(value) for key, value in data.items()}\n",
        "    new_data = {i: value for i, (key, value) in enumerate(tensor_dict.items())}\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLO8un7s-b8Q"
      },
      "source": [
        "Load the pickle files and get Dictionary data using `cover_dict()` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlmpz1xzfnJg"
      },
      "outputs": [],
      "source": [
        "heavy_dict = cover_dict('Heavy.pkl')\n",
        "light_dict = cover_dict('Light.pkl')\n",
        "antigen_dict = cover_dict(\"Antigen.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhZOVcZd-t7H"
      },
      "source": [
        "## **SMILES to Molecular Fingerprint Encoding**\n",
        "This script converts **SMILES representations of molecules** into **fixed-size numerical encodings** using **Morgan fingerprints**. These encodings are then stored as **PyTorch tensors** for machine learning applications.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Steps in the Process**\n",
        "1. **Convert SMILES to Molecular Representation**  \n",
        "   - `Chem.MolFromSmiles(smiles)`: Converts a SMILES string into an RDKit molecule object.\n",
        "2. **Generate Morgan Fingerprints**  \n",
        "   - `AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1280)`:  \n",
        "     - Uses **radius = 2** for capturing molecular neighborhoods.  \n",
        "     - Produces a **fixed-length (1280-bit) fingerprint** for each molecule.  \n",
        "3. **Store Encodings as Tensors**  \n",
        "   - Converts the fingerprints into **NumPy arrays**.  \n",
        "   - Wraps them in **PyTorch tensors** for ML compatibility.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Tensor Shape**\n",
        "- The final tensor, `sml_list1_enc`, has a shape of **(40, 1280)**:\n",
        "  - `40`: Number of molecules processed.\n",
        "  - `1280`: Length of the Morgan fingerprint for each molecule.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uok7VF9NJEWC",
        "outputId": "1c189ab5-0e7d-4d49-9ca5-6a3f0377b9d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n",
            "[09:52:05] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([40, 1280])"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from rdkit.Chem import MACCSkeys\n",
        "\n",
        "def smiles_to_encoding(smiles):\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "  morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1280)\n",
        "  encoding = np.array(morgan_fp)\n",
        "  return encoding\n",
        "\n",
        "sml_list1_enc = []\n",
        "sml_list2_enc = []\n",
        "for smile in sml_list1[:40]:\n",
        "  encoding = smiles_to_encoding(smile)\n",
        "  sml_list1_enc.append(encoding)\n",
        "\n",
        "sml_list1_enc = torch.tensor(np.array(sml_list1_enc))\n",
        "for smile in sml_list2[:40]:\n",
        "  encoding = smiles_to_encoding(smile)\n",
        "  sml_list2_enc.append(encoding)\n",
        "\n",
        "sml_list2_enc = torch.tensor(np.array(sml_list2_enc))\n",
        "\n",
        "sml_list1_enc.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvE2gQQq-_4C"
      },
      "source": [
        "## **Converting Dictionary Values to NumPy Arrays**\n",
        "\n",
        "\n",
        "### **Code Breakdown**\n",
        "1. **Extract Values from Dictionaries**  \n",
        "   - `[value for key, value in heavy_dict.items()]`:  \n",
        "     - Iterates through the dictionary and collects **only the values**.\n",
        "   - Similar steps apply to `light_dict` and `antigen_dict`.\n",
        "\n",
        "2. **Convert Lists to NumPy Arrays**  \n",
        "   - `np.array(...)` wraps the extracted values into **NumPy arrays** for numerical computation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnFdl28OfX4W"
      },
      "outputs": [],
      "source": [
        "t1 = np.array([value for key,value in heavy_dict.items()])\n",
        "\n",
        "t2 = np.array([value for key,value in light_dict.items()])\n",
        "t3 = np.array([value for key,value in antigen_dict.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abmPxolmmG6E",
        "outputId": "7712d96c-1f77-43e1-e3e8-38811d4d1299"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['index', 'ADC ID', 'ADC Name', 'Antibody Name',\n",
              "       'Antibody Heavy Chain Sequence', 'Antibody Light Chain Sequence',\n",
              "       'Antigen Sequence', 'Payload Isosmiles', 'Linker Isosmiles', 'DAR',\n",
              "       'label（10nm）', 'label（100nm）', 'label（1nm）', 'label（1000nm）',\n",
              "       'DAR_val'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 338,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inMK8f5D_N9Y"
      },
      "source": [
        "## **Preparing and Reshaping Input Data for Model Training**\n",
        "This code processes multiple tensors, **concatenates** them, and reshapes the final input tensor for a neural network.\n",
        "\n",
        "- **Converts arrays to PyTorch tensors** for efficient computation.\n",
        "- **Ensures consistent tensor shapes** before concatenation.\n",
        "- **Reshapes final input tensor** into the required format `(6, 40, 1280)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es182z5xHAfp",
        "outputId": "4abfd1d6-09b6-4743-e381-9360e2ce06b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([40])\n",
            "torch.Size([40, 1280]) torch.Size([40, 1280]) torch.Size([40, 1280]) torch.Size([40, 1280]) torch.Size([40, 1280]) torch.Size([40, 1280])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-356-d7d43c17cb86>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sml_list1 = torch.tensor(sml_list1_enc)\n",
            "<ipython-input-356-d7d43c17cb86>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sml_list2 = torch.tensor(sml_list2_enc)\n",
            "<ipython-input-356-d7d43c17cb86>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t1 = torch.tensor(t1[:40])\n",
            "<ipython-input-356-d7d43c17cb86>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t2 = torch.tensor(t2[:40])\n",
            "<ipython-input-356-d7d43c17cb86>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  t3 = torch.tensor(t3[:40])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 40, 1280])"
            ]
          },
          "execution_count": 356,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sml_list1 = torch.tensor(sml_list1_enc)\n",
        "sml_list2 = torch.tensor(sml_list2_enc)\n",
        "t1 = torch.tensor(t1[:40])\n",
        "t2 = torch.tensor(t2[:40])\n",
        "t3 = torch.tensor(t3[:40])\n",
        "t4 = torch.randn(40,1280)\n",
        "labels = torch.tensor(df['label（100nm）'].to_numpy()[:40])\n",
        "print(labels.shape)\n",
        "print(sml_list1.shape, sml_list2.shape, t1.shape, t2.shape, t3.shape, t4.shape)\n",
        "inputs = torch.cat([sml_list1,sml_list2, t1, t2, t3,t4])\n",
        "inputs.shape\n",
        "inputs = inputs.view(6,40,1280)\n",
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuWfT-1IgU8S"
      },
      "outputs": [],
      "source": [
        "model = CustomANN()\n",
        "optimizer = dc.optim.Adam(model.parameters(),lr = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU49p0t_uh02",
        "outputId": "32ee5fe7-0bb7-454a-d12c-a25545b2674b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "        0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "execution_count": 361,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtlDqs0viTEs",
        "outputId": "10b888b2-ad44-41db-d6f8-63cfbe5acac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.6924586296081543\n",
            "Epoch 2/10, Loss: 1.9352261272290302e-15\n",
            "Epoch 3/10, Loss: 3.386609027082028e-37\n",
            "Epoch 4/10, Loss: 0.0\n",
            "Epoch 5/10, Loss: 0.0\n",
            "Epoch 6/10, Loss: 0.0\n",
            "Epoch 7/10, Loss: 0.0\n",
            "Epoch 8/10, Loss: 0.0\n",
            "Epoch 9/10, Loss: 0.0\n",
            "Epoch 10/10, Loss: 0.0\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(inputs)\n",
        "\n",
        "  loss = F.binary_cross_entropy(outputs, labels.float())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMHhQ9vQE4kP"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
