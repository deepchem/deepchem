{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph_convolutional_networks_for_tox21_on_colab.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "https://github.com/deepchem/deepchem/blob/master/examples/notebooks/graph_convolutional_networks_for_tox21.ipynb",
          "timestamp": 1533163451822
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "R9PuATRRqO7T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Graph Convolutions For Tox21 on Google Colaboratory\n",
        "In this notebook, we first show how to install DeepChem on a Colab with Py27 or Py36 runtime. We then explore the use of TensorGraph to create graph convolutional models with DeepChem. In particular, we will build a graph convolutional network on the Tox21 dataset.\n",
        "\n",
        "Let's start with installing DeepChem."
      ]
    },
    {
      "metadata": {
        "id": "LGu5G1SY9hzv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "PYV=`python -c \"import sys;t='{v[0]}.{v[1]}'.format(v=list(sys.version_info[:2]));sys.stdout.write(t)\";`\n",
        "echo \"Python version $PYV detected\"\n",
        "if [ $PYV == \"2.7\" ]\n",
        "then\n",
        "  # Installing DeepChem for Python 2.7.\n",
        "  apt-get install -y libxrender-dev\n",
        "  apt-get install python-rdkit librdkit1 rdkit-data       # Install RDkit\n",
        "\n",
        "  pip install joblib simdna\n",
        "\n",
        "  git clone https://github.com/deepchem/deepchem.git      # Clone deepchem source code from GitHub\n",
        "  cd deepchem && python setup.py install  \n",
        "\n",
        "  ls -la /usr/local/lib/python2.7/dist-packages/deepchem/\n",
        "else\n",
        "  # Installing DeepChem for Python 3.6 using MiniConda.\n",
        "  wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O anaconda.sh;\n",
        "  chmod +x anaconda.sh\n",
        "  bash ./anaconda.sh -b -f -p /usr/local\n",
        "  conda install -y --prefix /usr/local -c conda-forge rdkit joblib simdna\n",
        "\n",
        "  git clone https://github.com/deepchem/deepchem.git      # Clone deepchem source code from GitHub\n",
        "  cd deepchem && python setup.py install\n",
        "  ls -la /usr/local/lib/python3.6/site-packages/deepchem\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3cX2OcRKhfC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Last step of installing DeepChem under Python 3.6\n",
        "\n",
        "import sys\n",
        "if sys.version_info[0] >= 3:\n",
        "    sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBVCwtHnsblw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's start with some basic imports to see if the install was successful. \n",
        "\n",
        "Note: Sometimes it is necessary to restart the runtime once after the initial install. After restarting, continue from the cell below."
      ]
    },
    {
      "metadata": {
        "id": "UnqurdY1qO7V",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import deepchem as dc\n",
        "from deepchem.models.tensorgraph.models.graph_models import GraphConvModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0JDwx5XqO7Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's use MoleculeNet to load the Tox21 dataset. We need to make sure to process the data in a way that graph convolutional networks can use For that, we make sure to set the featurizer option to 'GraphConv'. The MoleculeNet call will return a training set, an validation set, and a test set for us to use. The call also returns `transformers`, a list of data transformations that were applied to preprocess the dataset. (Most deep networks are quite finicky and require a set of data transformations to ensure that training proceeds stably.)"
      ]
    },
    {
      "metadata": {
        "id": "i3knXlDcqO7a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load Tox21 dataset\n",
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VBRQBRxqO7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now train a graph convolutional network on this dataset. DeepChem has the class `GraphConvModel` that wraps a standard graph convolutional architecture underneath the hood for user convenience. Let's instantiate an object of this class and train it on our dataset."
      ]
    },
    {
      "metadata": {
        "id": "c8H4WKvEqO7g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = GraphConvModel(\n",
        "    len(tox21_tasks), batch_size=50, mode='classification')\n",
        "# Set nb_epoch=10 for better results.\n",
        "model.fit(train_dataset, nb_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdACV2-bqO7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try to evaluate the performance of the model we've trained. For this, we need to define a metric, a measure of model performance. `dc.metrics` holds a collection of metrics already. For this dataset, it is standard to use the ROC-AUC score, the area under the receiver operating characteristic curve (which measures the tradeoff between precision and recall). Luckily, the ROC-AUC score is already available in DeepChem. \n",
        "\n",
        "To measure the performance of the model under this metric, we can use the convenience function `model.evaluate()`."
      ]
    },
    {
      "metadata": {
        "id": "5pAqT5b9qO7k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "metric = dc.metrics.Metric(\n",
        "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "print(\"Evaluating model\")\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "print(\"Training ROC-AUC Score: %f\" % train_scores[\"mean-roc_auc_score\"])\n",
        "valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
        "print(\"Validation ROC-AUC Score: %f\" % valid_scores[\"mean-roc_auc_score\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFeXiklVqO7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What's going on under the hood? Could we build `GraphConvModel` ourselves? Of course! The first step is to create a `TensorGraph` object. This object will hold the \"computational graph\" that defines the computation that a graph convolutional network will perform."
      ]
    },
    {
      "metadata": {
        "id": "lbd9UwBYqO7p",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from deepchem.models.tensorgraph.tensor_graph import TensorGraph\n",
        "\n",
        "tg = TensorGraph(use_queue=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rABquzvJqO7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now define the inputs to our model. Conceptually, graph convolutions just requires a the structure of the molecule in question and a vector of features for every atom that describes the local chemical environment. However in practice, due to TensorFlow's limitations as a general programming environment, we have to have some auxiliary information as well preprocessed.\n",
        "\n",
        "`atom_features` holds a feature vector of length 75 for each atom. The other feature inputs are required to support minibatching in TensorFlow. `degree_slice` is an indexing convenience that makes it easy to locate atoms from all molecules with a given degree. `membership` determines the membership of atoms in molecules (atom `i` belongs to molecule `membership[i]`). `deg_adjs` is a list that contains adjacency lists grouped by atom degree For more details, check out the [code](https://github.com/deepchem/deepchem/blob/master/deepchem/feat/mol_graphs.py).\n",
        "\n",
        "To define feature inputs in `TensorGraph`, we use the `Feature` layer. Conceptually, a `TensorGraph` is a mathematical graph composed of layer objects. `Features` layers have to be the root nodes of the graph since they consitute inputs."
      ]
    },
    {
      "metadata": {
        "id": "mVn_BaTuqO7u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from deepchem.models.tensorgraph.layers import Feature\n",
        "\n",
        "atom_features = Feature(shape=(None, 75))\n",
        "degree_slice = Feature(shape=(None, 2), dtype=tf.int32)\n",
        "membership = Feature(shape=(None,), dtype=tf.int32)\n",
        "\n",
        "deg_adjs = []\n",
        "for i in range(0, 10 + 1):\n",
        "    deg_adj = Feature(shape=(None, i + 1), dtype=tf.int32)\n",
        "    deg_adjs.append(deg_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYqqGSijqO7w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now implement the body of the graph convolutional network. `TensorGraph` has a number of layers that encode various graph operations. Namely, the `GraphConv`, `GraphPool` and `GraphGather` layers. We will also apply standard neural network layers such as `Dense` and `BatchNorm`.\n",
        "\n",
        "The layers we're adding effect a \"feature transformation\" that will create one vector for each molecule."
      ]
    },
    {
      "metadata": {
        "id": "e6qMhK2XqO7x",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from deepchem.models.tensorgraph.layers import Dense, GraphConv, BatchNorm\n",
        "from deepchem.models.tensorgraph.layers import GraphPool, GraphGather\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "gc1 = GraphConv(\n",
        "    64,\n",
        "    activation_fn=tf.nn.relu,\n",
        "    in_layers=[atom_features, degree_slice, membership] + deg_adjs)\n",
        "batch_norm1 = BatchNorm(in_layers=[gc1])\n",
        "gp1 = GraphPool(in_layers=[batch_norm1, degree_slice, membership] + deg_adjs)\n",
        "gc2 = GraphConv(\n",
        "    64,\n",
        "    activation_fn=tf.nn.relu,\n",
        "    in_layers=[gp1, degree_slice, membership] + deg_adjs)\n",
        "batch_norm2 = BatchNorm(in_layers=[gc2])\n",
        "gp2 = GraphPool(in_layers=[batch_norm2, degree_slice, membership] + deg_adjs)\n",
        "dense = Dense(out_channels=128, activation_fn=tf.nn.relu, in_layers=[gp2])\n",
        "batch_norm3 = BatchNorm(in_layers=[dense])\n",
        "readout = GraphGather(\n",
        "    batch_size=batch_size,\n",
        "    activation_fn=tf.nn.tanh,\n",
        "    in_layers=[batch_norm3, degree_slice, membership] + deg_adjs)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYT8tiy9qO71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now make predictions from the `TensorGraph` model. Tox21 is a multitask dataset. That is, there are 12 different datasets grouped together, which share many common molecules, but with different outputs for each. As a result, we have to add a separate output layer for each task. We will use a `for` loop over the `tox21_tasks` list to make this happen. We need to add labels for each\n",
        "\n",
        "We also have to define a loss for the model which tells the network the objective to minimize during training.\n",
        "\n",
        "We have to tell `TensorGraph` which layers are outputs with `TensorGraph.add_output(layer)`. Similarly, we tell the network its loss with `TensorGraph.set_loss(loss)`."
      ]
    },
    {
      "metadata": {
        "id": "yM1Nq6wkqO72",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from deepchem.models.tensorgraph.layers import Dense, SoftMax, \\\n",
        "    SoftMaxCrossEntropy, WeightedError, Stack\n",
        "from deepchem.models.tensorgraph.layers import Label, Weights\n",
        "\n",
        "costs = []\n",
        "labels = []\n",
        "for task in range(len(tox21_tasks)):\n",
        "    classification = Dense(\n",
        "        out_channels=2, activation_fn=None, in_layers=[readout])\n",
        "\n",
        "    softmax = SoftMax(in_layers=[classification])\n",
        "    tg.add_output(softmax)\n",
        "\n",
        "    label = Label(shape=(None, 2))\n",
        "    labels.append(label)\n",
        "    cost = SoftMaxCrossEntropy(in_layers=[label, classification])\n",
        "    costs.append(cost)\n",
        "all_cost = Stack(in_layers=costs, axis=1)\n",
        "weights = Weights(shape=(None, len(tox21_tasks)))\n",
        "loss = WeightedError(in_layers=[all_cost, weights])\n",
        "tg.set_loss(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuDxc9nIqO75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we've successfully defined our graph convolutional model in `TensorGraph`, we need to train it. We can call `fit()`, but we need to make sure that each minibatch of data populates all four `Feature` objects that we've created. For this, we need to create a Python generator that given a batch of data generates a dictionary whose keys are the `Feature` layers and whose values are Numpy arrays we'd like to use for this step of training."
      ]
    },
    {
      "metadata": {
        "id": "NaVNY7yiqO75",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from deepchem.metrics import to_one_hot\n",
        "from deepchem.feat.mol_graphs import ConvMol\n",
        "\n",
        "def data_generator(dataset, epochs=1, predict=False, pad_batches=True):\n",
        "  for epoch in range(epochs):\n",
        "    if not predict:\n",
        "        print('Starting epoch %i' % epoch)\n",
        "    for ind, (X_b, y_b, w_b, ids_b) in enumerate(\n",
        "        dataset.iterbatches(\n",
        "            batch_size, pad_batches=pad_batches, deterministic=True)):\n",
        "      d = {}\n",
        "      for index, label in enumerate(labels):\n",
        "        d[label] = to_one_hot(y_b[:, index])\n",
        "      d[weights] = w_b\n",
        "      multiConvMol = ConvMol.agglomerate_mols(X_b)\n",
        "      d[atom_features] = multiConvMol.get_atom_features()\n",
        "      d[degree_slice] = multiConvMol.deg_slice\n",
        "      d[membership] = multiConvMol.membership\n",
        "      for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
        "        d[deg_adjs[i - 1]] = multiConvMol.get_deg_adjacency_lists()[i]\n",
        "      yield d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uws1gPMsqO78",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we can train the model using `TensorGraph.fit_generator(generator)` which will use the generator we've defined to train the model."
      ]
    },
    {
      "metadata": {
        "id": "iN6T9-DzqO79",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Epochs set to 1 to render tutorials online.\n",
        "# Set epochs=10 for better results.\n",
        "tg.fit_generator(data_generator(train_dataset, epochs=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZdsmcN_QqO8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have trained our graph convolutional method, let's evaluate its performance. We again have to use our defined generator to evaluate model performance."
      ]
    },
    {
      "metadata": {
        "id": "uFHtJnLgqO8B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "metric = dc.metrics.Metric(\n",
        "    dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "def reshape_y_pred(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    TensorGraph.Predict returns a list of arrays, one for each output\n",
        "    We also have to remove the padding on the last batch\n",
        "    Metrics taks results of shape (samples, n_task, prob_of_class)\n",
        "    \"\"\"\n",
        "    n_samples = len(y_true)\n",
        "    retval = np.stack(y_pred, axis=1)\n",
        "    return retval[:n_samples]\n",
        "    \n",
        "\n",
        "print(\"Evaluating model\")\n",
        "train_predictions = tg.predict_on_generator(data_generator(train_dataset, predict=True))\n",
        "train_predictions = reshape_y_pred(train_dataset.y, train_predictions)\n",
        "train_scores = metric.compute_metric(train_dataset.y, train_predictions, train_dataset.w)\n",
        "print(\"Training ROC-AUC Score: %f\" % train_scores)\n",
        "\n",
        "valid_predictions = tg.predict_on_generator(data_generator(valid_dataset, predict=True))\n",
        "valid_predictions = reshape_y_pred(valid_dataset.y, valid_predictions)\n",
        "valid_scores = metric.compute_metric(valid_dataset.y, valid_predictions, valid_dataset.w)\n",
        "print(\"Valid ROC-AUC Score: %f\" % valid_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgL9qZGrqO8E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Success! The model we've constructed behaves nearly identically to `GraphConvModel`. If you're looking to build your own custom models, you can follow the example we've provided here to do so. We hope to see exciting constructions from your end soon!"
      ]
    }
  ]
}
