{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "__author__ = \"Joseph Gomes\"\n",
    "__copyright__ = \"Copyright 2016, Stanford University\"\n",
    "__license__ = \"LGPL\"\n",
    "\n",
    "import os\n",
    "import unittest\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "\n",
    "from deepchem import metrics\n",
    "from deepchem.datasets import Dataset\n",
    "from deepchem.featurizers.featurize import DataFeaturizer\n",
    "from deepchem.featurizers.featurize import FeaturizedSamples\n",
    "from deepchem.hyperparameters import HyperparamOpt\n",
    "from deepchem.metrics import Metric\n",
    "from deepchem.models import Model\n",
    "from deepchem.models.sklearn_models import SklearnModel\n",
    "from deepchem.transformers import NormalizationTransformer\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating temporary directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dir = tempfile.mkdtemp()\n",
    "samples_dir = tempfile.mkdtemp()\n",
    "train_dir = tempfile.mkdtemp()\n",
    "valid_dir = tempfile.mkdtemp()\n",
    "test_dir = tempfile.mkdtemp()\n",
    "model_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.featurizers.coulomb_matrices import CoulombMatrixEig\n",
    "compound_featurizers = [CoulombMatrixEig(23, remove_hydrogens=False)]\n",
    "complex_featurizers = []\n",
    "#task_types = {\"atomization_energy\": \"regression\"}\n",
    "tasks = [\"atomization_energy\"]\n",
    "task_type = \"regression\"\n",
    "task_types = {task: task_type for task in tasks}\n",
    "input_file = \"../datasets/gdb1k.sdf\"\n",
    "smiles_field = \"smiles\"\n",
    "mol_field = \"mol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load featurized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizers = compound_featurizers + complex_featurizers\n",
    "featurizer = DataFeaturizer(tasks=tasks,\n",
    "                            smiles_field=smiles_field,\n",
    "                            mol_field=mol_field,\n",
    "                            compound_featurizers=compound_featurizers,\n",
    "                            complex_featurizers=complex_featurizers, verbosity=\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "Reading structures from ../datasets/gdb1k.sdf.\n",
      "Loaded raw data frame from file.\n",
      "About to preprocess samples.\n",
      "Sharding and standardizing into shard-1 / 1 shards\n",
      "Currently featurizing feature_type: CoulombMatrixEig\n",
      "Featurizing sample 0\n",
      "Saving compounds to disk\n"
     ]
    }
   ],
   "source": [
    "featurized_samples = featurizer.featurize(input_file, feature_dir, samples_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Train, Validation, and Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepchem.splits import RandomSplitter\n",
    "random_splitter = RandomSplitter()\n",
    "train_samples, valid_samples, test_samples = random_splitter.train_valid_test_split(featurized_samples,\n",
    "    train_dir, valid_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(data_dir=train_dir, samples=train_samples, \n",
    "                        featurizers=featurizers, tasks=tasks)\n",
    "valid_dataset = Dataset(data_dir=valid_dir, samples=valid_samples, \n",
    "                        featurizers=featurizers, tasks=tasks)\n",
    "test_dataset = Dataset(data_dir=test_dir, samples=test_samples, \n",
    "                       featurizers=featurizers, tasks=tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_transformers = [NormalizationTransformer(transform_X=True, dataset=train_dataset)]\n",
    "output_transformers = [NormalizationTransformer(transform_y=True, dataset=train_dataset)]\n",
    "transformers = input_transformers + output_transformers\n",
    "for transformer in transformers:\n",
    "    transformer.transform(train_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(valid_dataset)\n",
    "for transformer in transformers:\n",
    "    transformer.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fit Random Forest with hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/1, Metric mean_absolute_error, Validation set 0: 1430.040028\n",
      "\tbest_validation_score so far: 1430.040028\n",
      "Best hyperparameters: (100, (23,), u'auto')\n",
      "train_score: 1416.482186\n",
      "validation_score: 1430.040028\n"
     ]
    }
   ],
   "source": [
    "def rf_model_builder(tasks, task_types, params_dict, model_dir, verbosity=None):\n",
    "    \"\"\"Builds random forests given hyperparameters.\n",
    "\n",
    "    Last two arguments only for tensorflow models and ignored.\n",
    "    \"\"\"\n",
    "    n_estimators = params_dict[\"n_estimators\"]\n",
    "    max_features = params_dict[\"max_features\"]\n",
    "    return SklearnModel(\n",
    "        tasks, task_types, params_dict, model_dir,\n",
    "        mode=\"regression\",\n",
    "        model_instance=RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                             max_features=max_features))\n",
    "\n",
    "params_dict = {\n",
    "    \"n_estimators\": [100],\n",
    "    \"data_shape\": [train_dataset.get_data_shape()],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    }\n",
    "\n",
    "metric = Metric(metrics.mean_absolute_error)\n",
    "optimizer = HyperparamOpt(rf_model_builder, tasks, task_types, verbosity=\"low\")       \n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(              \n",
    "    params_dict, train_dataset, valid_dataset, output_transformers,                     \n",
    "    metric, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/1, Metric mean_absolute_error, Validation set 0: 1495.176781\n",
      "\tbest_validation_score so far: 1495.176781\n",
      "Best hyperparameters: (u'laplacian', 0.0001, 0.0001)\n",
      "train_score: 1417.064172\n",
      "validation_score: 1495.176781\n"
     ]
    }
   ],
   "source": [
    "def kr_model_builder(tasks, task_types, params_dict, model_dir, verbosity=None):\n",
    "    \"\"\"Builds random forests given hyperparameters.\n",
    "\n",
    "    Last two arguments only for tensorflow models and ignored.\n",
    "    \"\"\"\n",
    "    kernel = params_dict[\"kernel\"]\n",
    "    alpha = params_dict[\"alpha\"]\n",
    "    gamma = params_dict[\"gamma\"]\n",
    "    return SklearnModel(\n",
    "        tasks, task_types, params_dict, model_dir,\n",
    "        mode=\"regression\",\n",
    "        model_instance=KernelRidge(alpha=alpha,kernel=kernel,gamma=gamma))\n",
    "\n",
    "params_dict = {\n",
    "    \"kernel\": [\"laplacian\"],\n",
    "    \"alpha\": [0.0001],\n",
    "    \"gamma\": [0.0001]\n",
    "    }\n",
    "\n",
    "metric = Metric(metrics.mean_absolute_error)\n",
    "optimizer = HyperparamOpt(kr_model_builder, tasks, task_types, verbosity=\"low\")       \n",
    "best_model, best_hyperparams, all_results = optimizer.hyperparam_search(              \n",
    "    params_dict, train_dataset, valid_dataset, output_transformers,                     \n",
    "    metric, logdir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
